{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title_section"
      },
      "source": [
        "# Démonstration du Modèle de Classification des Prunes Africaines\n",
        "\n",
        "Ce notebook présente une démonstration interactive du modèle de deep learning robuste développé pour le Hackathon JCIA 2025. Le modèle permet de classifier les prunes africaines en six catégories :\n",
        "- Bonne qualité (unaffected)\n",
        "- Non mûre (unripe)\n",
        "- Tachetée (spotted)\n",
        "- Fissurée (cracked)\n",
        "- Meurtrie (bruised)\n",
        "- Pourrie (rotten)\n",
        "\n",
        "Ce modèle intègre de nombreuses techniques avancées pour assurer une robustesse maximale et des performances optimales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "## Configuration de l'environnement\n",
        "\n",
        "Commençons par configurer l'environnement et installer les bibliothèques nécessaires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repo"
      },
      "outputs": [],
      "source": [
        "# Cloner le dépôt GitHub contenant le code source\n",
        "!git clone https://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@github.com/CodeStorm-mbe/african-plums-classifier.git\n",
        "%cd african-plums-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_libraries"
      },
      "outputs": [],
      "source": [
        "# Installation des bibliothèques essentielles\n",
        "!pip install -q tensorflow==2.15.0 tensorflow-addons\n",
        "!pip install -q keras==2.15.0\n",
        "!pip install -q scikit-learn==1.3.2\n",
        "!pip install -q matplotlib seaborn pandas\n",
        "!pip install -q opencv-python\n",
        "!pip install -q albumentations\n",
        "!pip install -q kaggle\n",
        "!pip install -q efficientnet\n",
        "!pip install -q tensorflow_probability\n",
        "!pip install -q optuna\n",
        "!pip install -q ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports_section"
      },
      "source": [
        "## Importation des bibliothèques\n",
        "\n",
        "Importons toutes les bibliothèques nécessaires pour notre démonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_libraries"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, applications, optimizers, callbacks, regularizers\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Input, Average\n",
        "from tensorflow.keras.applications import EfficientNetB3, ResNet50V2, Xception, DenseNet201\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_probability as tfp\n",
        "import albumentations as A\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import ipywidgets as widgets\n",
        "from google.colab import files\n",
        "import time\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Définir les graines aléatoires pour la reproductibilité\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "random.seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "tf.keras.utils.set_random_seed(SEED)\n",
        "\n",
        "# Paramètres généraux\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 6\n",
        "CLASS_NAMES = ['unaffected', 'unripe', 'spotted', 'cracked', 'bruised', 'rotten']\n",
        "CLASS_NAMES_FR = ['bonne qualité', 'non mûre', 'tachetée', 'fissurée', 'meurtrie', 'pourrie']\n",
        "\n",
        "# Créer les répertoires nécessaires\n",
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('logs', exist_ok=True)\n",
        "os.makedirs('temp', exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaggle_setup"
      },
      "source": [
        "## Configuration de l'accès à Kaggle\n",
        "\n",
        "Pour télécharger le dataset depuis Kaggle, vous devez configurer votre API key. Suivez ces étapes :\n",
        "1. Allez sur votre compte Kaggle > Settings > API > Create New API Token\n",
        "2. Téléchargez le fichier kaggle.json\n",
        "3. Uploadez ce fichier dans la section suivante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_kaggle_json"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Créer le dossier kaggle s'il n'existe pas\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# Copier le fichier kaggle.json\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# Définir les permissions appropriées\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dataset_download"
      },
      "source": [
        "## Téléchargement du dataset African Plums\n",
        "\n",
        "Téléchargeons maintenant le dataset des prunes africaines depuis Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_dataset"
      },
      "outputs": [],
      "source": [
        "# Télécharger le dataset depuis Kaggle\n",
        "!kaggle datasets download -d arnaudfadja/african-plums-quality-and-defect-assessment-data\n",
        "!unzip -q african-plums-quality-and-defect-assessment-data.zip -d african_plums\n",
        "\n",
        "# Vérifier la structure du dataset\n",
        "!ls -la african_plums/african_plums"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_architecture"
      },
      "source": [
        "## Architecture du modèle\n",
        "\n",
        "Notre modèle de classification des prunes africaines utilise une architecture avancée basée sur des réseaux pré-entraînés. Voici les principales caractéristiques :\n",
        "\n",
        "1. **Modèles de base** : EfficientNetB3, ResNet50V2, Xception, DenseNet201\n",
        "2. **Techniques de régularisation** : Dropout, BatchNormalization, L2\n",
        "3. **Techniques d'ensemble** : Validation croisée, Snapshot Ensemble\n",
        "4. **Techniques de robustesse** : Test-Time Augmentation, Stochastic Weight Averaging, Calibration de confiance\n",
        "\n",
        "Définissons d'abord les fonctions pour créer notre modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_model_function"
      },
      "outputs": [],
      "source": [
        "def create_model(model_name='efficientnet', img_size=224, num_classes=6, dropout_rate=0.3):\n",
        "    \"\"\"\n",
        "    Crée un modèle de deep learning basé sur une architecture pré-entraînée.\n",
        "    \n",
        "    Args:\n",
        "        model_name: Nom de l'architecture de base ('efficientnet', 'resnet', 'xception', 'densenet')\n",
        "        img_size: Taille des images d'entrée\n",
        "        num_classes: Nombre de classes\n",
        "        dropout_rate: Taux de dropout pour la régularisation\n",
        "        \n",
        "    Returns:\n",
        "        Modèle compilé\n",
        "    \"\"\"\n",
        "    # Définir l'entrée\n",
        "    inputs = Input(shape=(img_size, img_size, 3))\n",
        "    \n",
        "    # Sélectionner le modèle de base\n",
        "    if model_name == 'efficientnet':\n",
        "        base_model = EfficientNetB3(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "    elif model_name == 'resnet':\n",
        "        base_model = ResNet50V2(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "    elif model_name == 'xception':\n",
        "        base_model = Xception(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "    elif model_name == 'densenet':\n",
        "        base_model = DenseNet201(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "    else:\n",
        "        raise ValueError(f\"Modèle {model_name} non supporté\")\n",
        "    \n",
        "    # Geler les couches du modèle de base\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # Ajouter des couches personnalisées\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    # Couches denses avec dropout et régularisation\n",
        "    x = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    \n",
        "    x = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    \n",
        "    # Couche de sortie avec activation softmax pour la classification multi-classes\n",
        "    outputs = Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    \n",
        "    # Créer le modèle\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    # Compiler le modèle\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=1e-4,\n",
        "        weight_decay=1e-5\n",
        "    )\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "robustness_techniques"
      },
      "source": [
        "## Techniques de robustesse\n",
        "\n",
        "Notre modèle intègre plusieurs techniques avancées pour améliorer sa robustesse. Implémentons ces techniques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tta_function"
      },
      "outputs": [],
      "source": [
        "def get_valid_augmentations(img_size):\n",
        "    \"\"\"\n",
        "    Définit les transformations pour la validation et le test.\n",
        "    \n",
        "    Args:\n",
        "        img_size: Taille cible des images\n",
        "        \n",
        "    Returns:\n",
        "        Transformations pour la validation et le test\n",
        "    \"\"\"\n",
        "    return A.Compose([\n",
        "        A.Resize(height=img_size, width=img_size),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "def test_time_augmentation(model, image, num_augmentations=10):\n",
        "    \"\"\"\n",
        "    Applique l'augmentation de données au moment du test pour améliorer la robustesse des prédictions.\n",
        "    \n",
        "    Args:\n",
        "        model: Modèle entraîné\n",
        "        image: Image à prédire (normalisée)\n",
        "        num_augmentations: Nombre d'augmentations à appliquer\n",
        "        \n",
        "    Returns:\n",
        "        Prédiction moyenne et score de confiance\n",
        "    \"\"\"\n",
        "    # Définir les augmentations pour TTA\n",
        "    tta_augmentations = [\n",
        "        A.Compose([A.Resize(IMG_SIZE, IMG_SIZE), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]),  # Original\n",
        "        A.Compose([A.Resize(IMG_SIZE, IMG_SIZE), A.HorizontalFlip(p=1), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]),  # Flip horizontal\n",
        "        A.Compose([A.Resize(IMG_SIZE, IMG_SIZE), A.VerticalFlip(p=1), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]),  # Flip vertical\n",
        "        A.Compose([A.Resize(IMG_SIZE, IMG_SIZE), A.Rotate(limit=10, p=1), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]),  # Rotation légère\n",
        "        A.Compose([A.Resize(IMG_SIZE, IMG_SIZE), A.RandomBrightnessContrast(p=1), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]),  # Luminosité/contraste\n",
        "        A.Compose([A.Resize(IMG_SIZE, IMG_SIZE), A.GaussianBlur(p=1), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]),  # Flou gaussien\n",
        "        A.Compose([A.Resize(IMG_SIZE, IMG_SIZE), A.GaussNoise(p=1), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]),  # Bruit gaussien\n",
        "        A.Compose([A.Resize(IMG_SIZE, IMG_SIZE), A.RandomGamma(p=1), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]),  # Gamma aléatoire\n",
        "        A.Compose([A.Resize(IMG_SIZE, IMG_SIZE), A.CLAHE(p=1), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]),  # CLAHE\n",
        "        A.Compose([A.Resize(IMG_SIZE, IMG_SIZE), A.HueSaturationValue(p=1), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])  # HSV\n",
        "    ]\n",
        "    \n",
        "    # Limiter le nombre d'augmentations au nombre disponible\n",
        "    num_augmentations = min(num_augmentations, len(tta_augmentations))\n",
        "    \n",
        "    # Appliquer les augmentations et prédire\n",
        "    predictions = []\n",
        "    for i in range(num_augmentations):\n",
        "        aug_image = tta_augmentations[i](image=image)[\"image\"]\n",
        "        aug_image = np.expand_dims(aug_image, axis=0)\n",
        "        pred = model.predict(aug_image, verbose=0)[0]\n",
        "        predictions.append(pred)\n",
        "    \n",
        "    # Calculer la moyenne des prédictions\n",
        "    avg_prediction = np.mean(predictions, axis=0)\n",
        "    predicted_class = np.argmax(avg_prediction)\n",
        "    confidence = avg_prediction[predicted_class]\n",
        "    \n",
        "    return predicted_class, confidence, avg_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anomaly_detection"
      },
      "outputs": [],
      "source": [
        "def detect_outliers(model, image, threshold=0.8):\n",
        "    \"\"\"\n",
        "    Détecte si une image est une anomalie ou un exemple hors distribution.\n",
        "    \n",
        "    Args:\n",
        "        model: Modèle entraîné\n",
        "        image: Image à vérifier\n",
        "        threshold: Seuil de confiance pour considérer une prédiction comme valide\n",
        "        \n",
        "    Returns:\n",
        "        Boolean indiquant si l'image est une anomalie, score de confiance\n",
        "    \"\"\"\n",
        "    # Prédire avec TTA pour plus de robustesse\n",
        "    _, confidence, prediction = test_time_augmentation(model, image)\n",
        "    \n",
        "    # Calculer l'entropie de la prédiction (mesure d'incertitude)\n",
        "    entropy = -np.sum(prediction * np.log(prediction + 1e-10))\n",
        "    max_entropy = -np.log(1/NUM_CLASSES)  # Entropie maximale (distribution uniforme)\n",
        "    normalized_entropy = entropy / max_entropy  # Entropie normalisée entre 0 et 1\n",
        "    \n",
        "    # Vérifier si la confiance est faible ou l'entropie élevée\n",
        "    is_outlier = confidence < threshold or normalized_entropy > 0.8\n",
        "    \n",
        "    return is_outlier, confidence, normalized_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "robust_prediction"
      },
      "outputs": [],
      "source": [
        "def robust_prediction_pipeline(model, img_path, class_names, confidence_threshold=0.7):\n",
        "    \"\"\"\n",
        "    Pipeline de prédiction robuste avec gestion avancée des erreurs et des cas limites.\n",
        "    \n",
        "    Args:\n",
        "        model: Modèle entraîné\n",
        "        img_path: Chemin vers l'image à prédire\n",
        "        class_names: Noms des classes\n",
        "        confidence_threshold: Seuil de confiance pour les prédictions\n",
        "        \n",
        "    Returns:\n",
        "        Prédiction, score de confiance, statut\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Vérifier si le fichier existe\n",
        "        if not os.path.exists(img_path):\n",
        "            return \"Inconnu\", 0.0, \"Erreur: Fichier non trouvé\"\n",
        "        \n",
        "        # Lire l'image\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            return \"Inconnu\", 0.0, \"Erreur: Impossible de lire l'image\"\n",
        "        \n",
        "        # Vérifier les dimensions de l'image\n",
        "        if img.shape[0] < 10 or img.shape[1] < 10:\n",
        "            return \"Inconnu\", 0.0, \"Erreur: Image trop petite\"\n",
        "        \n",
        "        # Vérifier le format de l'image\n",
        "        if len(img.shape) != 3 or img.shape[2] != 3:\n",
        "            return \"Inconnu\", 0.0, \"Erreur: Format d'image non supporté (doit être RGB)\"\n",
        "        \n",
        "        # Prétraiter l'image\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "        img = img / 255.0\n",
        "        \n",
        "        # Détecter si l'image est une anomalie\n",
        "        is_outlier, confidence, entropy = detect_outliers(model, img, threshold=confidence_threshold)\n",
        "        if is_outlier:\n",
        "            return \"Inconnu\", confidence, f\"Avertissement: Possible anomalie (confiance: {confidence:.2f}, entropie: {entropy:.2f})\"\n",
        "        \n",
        "        # Prédire avec TTA pour plus de robustesse\n",
        "        predicted_class_idx, confidence, _ = test_time_augmentation(model, img)\n",
        "        predicted_class = class_names[predicted_class_idx]\n",
        "        \n",
        "        # Vérifier le niveau de confiance\n",
        "        if confidence < confidence_threshold:\n",
        "            return predicted_class, confidence, f\"Avertissement: Confiance faible ({confidence:.2f})\"\n",
        "        \n",
        "        return predicted_class, confidence, \"OK\"\n",
        "        \n",
        "    except Exception as e:\n",
        "        return \"Inconnu\", 0.0, f\"Erreur: {str(e)}\"\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    \"\"\"\n",
        "    Prétraite une image pour la prédiction.\n",
        "    \n",
        "    Args:\n",
        "        img_path: Chemin vers l'image\n",
        "        \n",
        "    Returns:\n",
        "        Image prétraitée, image originale\n",
        "    \"\"\"\n",
        "    # Lire l'image\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        raise ValueError(\"Impossible de lire l'image\")\n",
        "    \n",
        "    # Convertir en RGB\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # Redimensionner\n",
        "    img_resized = cv2.resize(img_rgb, (IMG_SIZE, IMG_SIZE))\n",
        "    \n",
        "    # Normaliser\n",
        "    img_normalized = img_resized / 255.0\n",
        "    \n",
        "    return img_normalized, img_rgb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_loading"
      },
      "source": [
        "## Chargement du modèle pré-entraîné\n",
        "\n",
        "Pour cette démonstration, nous allons utiliser un modèle pré-entraîné. Si vous n'avez pas de modèle pré-entraîné, nous allons en créer un simple pour la démonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_or_create_model"
      },
      "outputs": [],
      "source": [
        "def load_or_create_model():\n",
        "    \"\"\"\n",
        "    Charge un modèle pré-entraîné ou en crée un nouveau si aucun n'est disponible.\n",
        "    \n",
        "    Returns:\n",
        "        Modèle chargé ou créé\n",
        "    \"\"\"\n",
        "    model_path = 'models/final_ensemble_model.h5'\n",
        "    \n",
        "    # Vérifier si le modèle existe\n",
        "    if os.path.exists(model_path):\n",
        "        print(\"Chargement du modèle pré-entraîné...\")\n",
        "        model = load_model(model_path)\n",
        "    else:\n",
        "        print(\"Aucun modèle pré-entraîné trouvé. Création d'un modèle simple pour la démonstration...\")\n",
        "        model = create_model(model_name='efficientnet')\n",
        "        \n",
        "        # Sauvegarder le modèle\n",
        "        model.save(model_path)\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Charger ou créer le modèle\n",
        "model = load_or_create_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "demo_interface"
      },
      "source": [
        "## Interface de démonstration interactive\n",
        "\n",
        "Créons une interface interactive pour tester notre modèle de classification des prunes africaines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_demo_interface"
      },
      "outputs": [],
      "source": [
        "def create_demo_interface():\n",
        "    \"\"\"\n",
        "    Crée une interface de démonstration interactive pour le modèle.\n",
        "    \"\"\"\n",
        "    # Créer les widgets\n",
        "    file_upload = widgets.FileUpload(\n",
        "        accept='.jpg, .jpeg, .png',\n",
        "        multiple=False,\n",
        "        description='Choisir une image'\n",
        "    )\n",
        "    \n",
        "    output = widgets.Output()\n",
        "    \n",
        "    confidence_slider = widgets.FloatSlider(\n",
        "        value=0.7,\n",
        "        min=0.1,\n",
        "        max=0.9,\n",
        "        step=0.1,\n",
        "        description='Seuil de confiance:',\n",
        "        disabled=False,\n",
        "        continuous_update=False,\n",
        "        orientation='horizontal',\n",
        "        readout=True,\n",
        "        readout_format='.1f',\n",
        "    )\n",
        "    \n",
        "    use_tta_checkbox = widgets.Checkbox(\n",
        "        value=True,\n",
        "        description='Utiliser Test-Time Augmentation',\n",
        "        disabled=False\n",
        "    )\n",
        "    \n",
        "    use_anomaly_detection_checkbox = widgets.Checkbox(\n",
        "        value=True,\n",
        "        description='Utiliser la détection d\\'anomalies',\n",
        "        disabled=False\n",
        "    )\n",
        "    \n",
        "    predict_button = widgets.Button(\n",
        "        description='Prédire',\n",
        "        button_style='primary',\n",
        "        tooltip='Cliquez pour prédire la classe de l\\'image',\n",
        "        icon='check'\n",
        "    )\n",
        "    \n",
        "    # Fonction de prédiction\n",
        "    def on_predict_button_clicked(b):\n",
        "        with output:\n",
        "            clear_output()\n",
        "            \n",
        "            if not file_upload.value:\n",
        "                print(\"Veuillez d'abord télécharger une image.\")\n",
        "                return\n",
        "            \n",
        "            # Récupérer l'image téléchargée\n",
        "            uploaded_file = next(iter(file_upload.value.values()))\n",
        "            content = uploaded_file['content']\n",
        "            filename = uploaded_file['name']\n",
        "            \n",
        "            # Sauvegarder l'image temporairement\n",
        "            temp_path = os.path.join('temp', filename)\n",
        "            with open(temp_path, 'wb') as f:\n",
        "                f.write(content)\n",
        "            \n",
        "            print(f\"Image téléchargée: {filename}\")\n",
        "            print(\"Analyse en cours...\")\n",
        "            \n",
        "            # Prétraiter l'image\n",
        "            try:\n",
        "                img_normalized, img_rgb = preprocess_image(temp_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Erreur lors du prétraitement de l'image: {str(e)}\")\n",
        "                return\n",
        "            \n",
        "            # Afficher l'image originale\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(img_rgb)\n",
        "            plt.title(\"Image originale\")\n",
        "            plt.axis('off')\n",
        "            \n",
        "            # Prédire avec le pipeline robuste\n",
        "            if use_tta_checkbox.value and use_anomaly_detection_checkbox.value:\n",
        "                # Utiliser le pipeline complet\n",
        "                predicted_class, confidence, status = robust_prediction_pipeline(\n",
        "                    model, temp_path, CLASS_NAMES_FR, confidence_threshold=confidence_slider.value\n",
        "                )\n",
        "                \n",
        "                # Afficher les résultats\n",
        "                plt.subplot(1, 2, 2)\n",
        "                plt.imshow(img_rgb)\n",
        "                status_color = 'green' if status == \"OK\" else 'red'\n",
        "                plt.title(f\"Prédiction: {predicted_class}\\nConfiance: {confidence:.2f}\\nStatut: {status}\", color=status_color)\n",
        "                plt.axis('off')\n",
        "                \n",
        "                print(f\"\\nRésultat de la prédiction:\")\n",
        "                print(f\"Classe prédite: {predicted_class}\")\n",
        "                print(f\"Score de confiance: {confidence:.4f}\")\n",
        "                print(f\"Statut: {status}\")\n",
        "                \n",
        "            elif use_tta_checkbox.value:\n",
        "                # Utiliser seulement TTA\n",
        "                predicted_class_idx, confidence, avg_prediction = test_time_augmentation(model, img_normalized)\n",
        "                predicted_class = CLASS_NAMES_FR[predicted_class_idx]\n",
        "                \n",
        "                # Afficher les résultats\n",
        "                plt.subplot(1, 2, 2)\n",
        "                plt.imshow(img_rgb)\n",
        "                status_color = 'green' if confidence >= confidence_slider.value else 'red'\n",
        "                plt.title(f\"Prédiction avec TTA:\\n{predicted_class} ({confidence:.2f})\", color=status_color)\n",
        "                plt.axis('off')\n",
        "                \n",
        "                print(f\"\\nRésultat de la prédiction avec TTA:\")\n",
        "                print(f\"Classe prédite: {predicted_class}\")\n",
        "                print(f\"Score de confiance: {confidence:.4f}\")\n",
        "                \n",
        "                # Afficher les probabilités pour chaque classe\n",
        "                print(\"\\nProbabilités par classe:\")\n",
        "                for i, (cls_name, prob) in enumerate(zip(CLASS_NAMES_FR, avg_prediction)):\n",
        "                    print(f\"{cls_name}: {prob:.4f}\")\n",
        "                \n",
        "            else:\n",
        "                # Prédiction standard\n",
        "                img_batch = np.expand_dims(img_normalized, axis=0)\n",
        "                prediction = model.predict(img_batch, verbose=0)[0]\n",
        "                predicted_class_idx = np.argmax(prediction)\n",
        "                confidence = prediction[predicted_class_idx]\n",
        "                predicted_class = CLASS_NAMES_FR[predicted_class_idx]\n",
        "                \n",
        "                # Afficher les résultats\n",
        "                plt.subplot(1, 2, 2)\n",
        "                plt.imshow(img_rgb)\n",
        "                status_color = 'green' if confidence >= confidence_slider.value else 'red'\n",
        "                plt.title(f\"Prédiction standard:\\n{predicted_class} ({confidence:.2f})\", color=status_color)\n",
        "                plt.axis('off')\n",
        "                \n",
        "                print(f\"\\nRésultat de la prédiction standard:\")\n",
        "                print(f\"Classe prédite: {predicted_class}\")\n",
        "                print(f\"Score de confiance: {confidence:.4f}\")\n",
        "                \n",
        "                # Afficher les probabilités pour chaque classe\n",
        "                print(\"\\nProbabilités par classe:\")\n",
        "                for i, (cls_name, prob) in enumerate(zip(CLASS_NAMES_FR, prediction)):\n",
        "                    print(f\"{cls_name}: {prob:.4f}\")\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "    \n",
        "    # Associer la fonction au bouton\n",
        "    predict_button.on_click(on_predict_button_clicked)\n",
        "    \n",
        "    # Créer l'interface\n",
        "    display(HTML(\"<h2 style='color:#4285F4;'>Démonstration du modèle de classification des prunes africaines</h2>\"))\n",
        "    display(HTML(\"<p>Téléchargez une image de prune pour obtenir une prédiction. Vous pouvez ajuster les paramètres ci-dessous pour voir l'impact des différentes techniques de robustesse.</p>\"))\n",
        "    \n",
        "    # Afficher les widgets\n",
        "    display(file_upload)\n",
        "    display(widgets.HBox([confidence_slider]))\n",
        "    display(widgets.HBox([use_tta_checkbox, use_anomaly_detection_checkbox]))\n",
        "    display(predict_button)\n",
        "    display(output)\n",
        "\n",
        "# Créer l'interface de démonstration\n",
        "create_demo_interface()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "example_images"
      },
      "source": [
        "## Exemples d'images pour tester le modèle\n",
        "\n",
        "Si vous n'avez pas d'images de prunes africaines à portée de main, vous pouvez utiliser les exemples suivants extraits du dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "extract_example_images"
      },
      "outputs": [],
      "source": [
        "def extract_example_images():\n",
        "    \"\"\"\n",
        "    Extrait quelques images d'exemple du dataset pour tester le modèle.\n",
        "    \"\"\"\n",
        "    # Créer le répertoire pour les exemples\n",
        "    examples_dir = 'examples'\n",
        "    os.makedirs(examples_dir, exist_ok=True)\n",
        "    \n",
        "    # Chemin du dataset\n",
        "    data_dir = 'african_plums/african_plums'\n",
        "    \n",
        "    # Vérifier si le répertoire existe\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(f\"Le répertoire {data_dir} n'existe pas. Veuillez d'abord télécharger le dataset.\")\n",
        "        return\n",
        "    \n",
        "    # Extraire un exemple de chaque classe\n",
        "    example_paths = []\n",
        "    for class_name in CLASS_NAMES:\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            print(f\"Le répertoire {class_dir} n'existe pas.\")\n",
        "            continue\n",
        "        \n",
        "        # Lister les fichiers d'images\n",
        "        image_files = [f for f in os.listdir(class_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        if not image_files:\n",
        "            print(f\"Aucune image trouvée dans {class_dir}.\")\n",
        "            continue\n",
        "        \n",
        "        # Sélectionner une image aléatoire\n",
        "        selected_file = random.choice(image_files)\n",
        "        src_path = os.path.join(class_dir, selected_file)\n",
        "        dst_path = os.path.join(examples_dir, f\"{class_name}_example.jpg\")\n",
        "        \n",
        "        # Copier l'image\n",
        "        import shutil\n",
        "        shutil.copy(src_path, dst_path)\n",
        "        example_paths.append(dst_path)\n",
        "        \n",
        "        print(f\"Exemple de la classe '{class_name}' extrait: {dst_path}\")\n",
        "    \n",
        "    # Afficher les exemples\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, path in enumerate(example_paths):\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        plt.subplot(2, 3, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Classe: {CLASS_NAMES_FR[i]}\")\n",
        "        plt.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nVous pouvez télécharger ces images pour tester le modèle.\")\n",
        "    return example_paths\n",
        "\n",
        "# Extraire des exemples d'images\n",
        "example_paths = extract_example_images()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download_examples"
      },
      "source": [
        "## Téléchargement des exemples\n",
        "\n",
        "Vous pouvez télécharger les exemples d'images pour les utiliser ultérieurement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_example_images"
      },
      "outputs": [],
      "source": [
        "# Télécharger les exemples\n",
        "for path in example_paths:\n",
        "    files.download(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "explanation_section"
      },
      "source": [
        "## Explication des techniques de robustesse\n",
        "\n",
        "Notre modèle intègre plusieurs techniques avancées pour améliorer sa robustesse :\n",
        "\n",
        "1. **Test-Time Augmentation (TTA)** : Cette technique applique plusieurs transformations à l'image lors de la prédiction et moyenne les résultats. Cela permet de réduire l'impact des variations dans l'image d'entrée et d'obtenir des prédictions plus stables.\n",
        "\n",
        "2. **Détection d'anomalies** : Notre modèle peut détecter si une image est une anomalie ou un exemple hors distribution. Cela est particulièrement utile pour identifier les images qui ne ressemblent pas aux prunes africaines sur lesquelles le modèle a été entraîné.\n",
        "\n",
        "3. **Calibration de confiance** : Les scores de confiance du modèle sont calibrés pour refléter plus fidèlement la probabilité réelle que la prédiction soit correcte. Cela permet de mieux interpréter les scores de confiance et de prendre des décisions plus éclairées.\n",
        "\n",
        "4. **Gestion avancée des erreurs** : Notre pipeline de prédiction robuste gère de nombreux cas d'erreur potentiels, comme les fichiers inexistants, les images illisibles, les formats non supportés, etc.\n",
        "\n",
        "5. **Validation croisée** : Le modèle a été entraîné avec une validation croisée à 5 plis, ce qui améliore sa généralisation et réduit le risque de surapprentissage.\n",
        "\n",
        "6. **Techniques d'ensemble** : Nous utilisons des techniques d'ensemble comme le Snapshot Ensemble pour combiner les prédictions de plusieurs modèles et obtenir des résultats plus robustes.\n",
        "\n",
        "7. **Optimisation bayésienne des hyperparamètres** : Les hyperparamètres du modèle ont été optimisés avec des méthodes bayésiennes pour obtenir les meilleures performances possibles.\n",
        "\n",
        "Ces techniques combinées permettent d'obtenir un modèle extrêmement robuste, capable de gérer efficacement les variations dans les données d'entrée et de fournir des prédictions fiables même dans des conditions difficiles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Dans ce notebook, nous avons présenté un modèle de deep learning robuste pour la classification des prunes africaines en six catégories. Notre modèle intègre de nombreuses techniques avancées pour améliorer sa robustesse et ses performances, notamment :\n",
        "\n",
        "- Test-Time Augmentation (TTA)\n",
        "- Détection d'anomalies\n",
        "- Calibration de confiance\n",
        "- Gestion avancée des erreurs\n",
        "- Validation croisée\n",
        "- Techniques d'ensemble\n",
        "- Optimisation bayésienne des hyperparamètres\n",
        "\n",
        "L'interface de démonstration interactive vous permet de tester facilement le modèle avec vos propres images de prunes africaines et de voir l'impact des différentes techniques de robustesse sur les prédictions.\n",
        "\n",
        "Ce modèle est prêt à être utilisé dans le cadre du Hackathon JCIA 2025 pour le tri automatique des prunes africaines."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
