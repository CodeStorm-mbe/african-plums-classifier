{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header_title"
      },
      "source": [
        "# Hackathon JCIA 2025 - Tri Automatique des Prunes Africaines\n",
        "\n",
        "Ce notebook présente un modèle de deep learning robuste pour la classification des prunes africaines en six catégories:\n",
        "- Bonne qualité (unaffected)\n",
        "- Non mûre (unripe)\n",
        "- Tachetée (spotted)\n",
        "- Fissurée (cracked)\n",
        "- Meurtrie (bruised)\n",
        "- Pourrie (rotten)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "## Configuration de l'environnement\n",
        "\n",
        "Commençons par configurer l'environnement et installer les bibliothèques nécessaires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repo"
      },
      "outputs": [],
      "source": [
        "# Cloner le dépôt GitHub contenant le code source\n",
        "!git clone https://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@github.com/CodeStorm-mbe/african-plums-classifier.git\n",
        "%cd african-plums-classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_libraries"
      },
      "outputs": [],
      "source": [
        "# Installation des bibliothèques essentielles\n",
        "!pip install -q tensorflow==2.15.0 tensorflow-addons\n",
        "!pip install -q keras==2.15.0\n",
        "!pip install -q scikit-learn==1.3.2\n",
        "!pip install -q matplotlib seaborn pandas\n",
        "!pip install -q opencv-python\n",
        "!pip install -q albumentations\n",
        "!pip install -q kaggle\n",
        "!pip install -q efficientnet\n",
        "!pip install -q tensorflow_probability\n",
        "!pip install -q wandb\n",
        "!pip install -q optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaggle_setup"
      },
      "source": [
        "### Configuration de l'accès à Kaggle\n",
        "\n",
        "Pour télécharger le dataset depuis Kaggle, vous devez configurer votre API key. Suivez ces étapes :\n",
        "1. Allez sur votre compte Kaggle > Settings > API > Create New API Token\n",
        "2. Téléchargez le fichier kaggle.json\n",
        "3. Uploadez ce fichier dans la section suivante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_kaggle_json"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Créer le dossier kaggle s'il n'existe pas\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# Copier le fichier kaggle.json\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# Définir les permissions appropriées\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dataset_download"
      },
      "source": [
        "### Téléchargement du dataset African Plums\n",
        "\n",
        "Téléchargeons maintenant le dataset des prunes africaines depuis Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_dataset"
      },
      "outputs": [],
      "source": [
        "# Télécharger le dataset depuis Kaggle\n",
        "!kaggle datasets download -d arnaudfadja/african-plums-quality-and-defect-assessment-data\n",
        "!unzip -q african-plums-quality-and-defect-assessment-data.zip -d african_plums\n",
        "\n",
        "# Vérifier la structure du dataset\n",
        "!ls -la african_plums"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports_section"
      },
      "source": [
        "## Importation des bibliothèques\n",
        "\n",
        "Importons toutes les bibliothèques nécessaires pour notre modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_libraries"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, applications, optimizers, callbacks, regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB3, ResNet50V2, Xception, DenseNet201\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Input\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.utils import class_weight\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_probability as tfp\n",
        "import albumentations as A\n",
        "from albumentations.tensorflow import ToTensorV2\n",
        "import time\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Définir les graines aléatoires pour la reproductibilité\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "random.seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "tf.keras.utils.set_random_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "params_section"
      },
      "source": [
        "## Configuration des paramètres du modèle\n",
        "\n",
        "Définissons les paramètres généraux pour notre modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_params"
      },
      "outputs": [],
      "source": [
        "# Paramètres généraux\n",
        "IMG_SIZE = 224  # Taille des images d'entrée\n",
        "BATCH_SIZE = 32  # Taille des batchs\n",
        "EPOCHS = 50  # Nombre d'époques maximum\n",
        "LEARNING_RATE = 1e-4  # Taux d'apprentissage initial\n",
        "NUM_CLASSES = 6  # Nombre de classes (catégories de prunes)\n",
        "VALIDATION_SPLIT = 0.2  # Proportion des données pour la validation\n",
        "TEST_SPLIT = 0.1  # Proportion des données pour le test\n",
        "N_FOLDS = 5  # Nombre de folds pour la validation croisée\n",
        "PATIENCE = 10  # Patience pour l'early stopping\n",
        "\n",
        "# Chemins des données\n",
        "DATA_DIR = 'african_plums/african_plums'\n",
        "MODELS_DIR = 'models'\n",
        "LOGS_DIR = 'logs'\n",
        "\n",
        "# Créer les répertoires nécessaires s'ils n'existent pas\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(LOGS_DIR, exist_ok=True)\n",
        "\n",
        "# Noms des classes\n",
        "CLASS_NAMES = ['unaffected', 'unripe', 'spotted', 'cracked', 'bruised', 'rotten']\n",
        "\n",
        "# Vérifier la structure du répertoire des données\n",
        "!ls -la $DATA_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_exploration"
      },
      "source": [
        "## Exploration et préparation des données\n",
        "\n",
        "Explorons le dataset et préparons les données pour l'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data_function"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_data(data_dir, img_size):\n",
        "    \"\"\"\n",
        "    Charge et prétraite les images du dataset.\n",
        "    \n",
        "    Args:\n",
        "        data_dir: Chemin vers le répertoire des données\n",
        "        img_size: Taille cible des images\n",
        "        \n",
        "    Returns:\n",
        "        X: Images prétraitées\n",
        "        y: Étiquettes correspondantes\n",
        "        class_weights: Poids des classes pour gérer le déséquilibre\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    \n",
        "    # Parcourir chaque classe\n",
        "    for idx, class_name in enumerate(CLASS_NAMES):\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        if not os.path.exists(class_dir):\n",
        "            print(f\"Le répertoire {class_dir} n'existe pas.\")\n",
        "            continue\n",
        "            \n",
        "        print(f\"Chargement des images de la classe {class_name}...\")\n",
        "        class_files = os.listdir(class_dir)\n",
        "        \n",
        "        for file_name in class_files:\n",
        "            if file_name.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                img_path = os.path.join(class_dir, file_name)\n",
        "                \n",
        "                # Lire et prétraiter l'image\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is None:\n",
        "                    print(f\"Impossible de lire l'image: {img_path}\")\n",
        "                    continue\n",
        "                    \n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                img = cv2.resize(img, (img_size, img_size))\n",
        "                img = img / 255.0  # Normalisation\n",
        "                \n",
        "                images.append(img)\n",
        "                labels.append(idx)\n",
        "    \n",
        "    # Convertir en tableaux numpy\n",
        "    X = np.array(images, dtype=np.float32)\n",
        "    y = np.array(labels)\n",
        "    \n",
        "    # Calculer les poids des classes pour gérer le déséquilibre\n",
        "    class_weights = class_weight.compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=np.unique(y),\n",
        "        y=y\n",
        "    )\n",
        "    class_weights = dict(enumerate(class_weights))\n",
        "    \n",
        "    print(f\"Données chargées: {X.shape[0]} images, {len(np.unique(y))} classes\")\n",
        "    return X, y, class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "explore_dataset_function"
      },
      "outputs": [],
      "source": [
        "def explore_dataset(X, y, class_names):\n",
        "    \"\"\"\n",
        "    Explore le dataset et affiche des statistiques et visualisations.\n",
        "    \n",
        "    Args:\n",
        "        X: Images prétraitées\n",
        "        y: Étiquettes correspondantes\n",
        "        class_names: Noms des classes\n",
        "    \"\"\"\n",
        "    print(f\"Forme des données: {X.shape}\")\n",
        "    print(f\"Nombre total d'images: {X.shape[0]}\")\n",
        "    \n",
        "    # Distribution des classes\n",
        "    unique, counts = np.unique(y, return_counts=True)\n",
        "    class_distribution = dict(zip(class_names, counts))\n",
        "    \n",
        "    print(\"\\nDistribution des classes:\")\n",
        "    for class_name, count in class_distribution.items():\n",
        "        print(f\"{class_name}: {count} images ({count/len(y)*100:.2f}%)\")\n",
        "    \n",
        "    # Visualiser la distribution des classes\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x=list(class_distribution.keys()), y=list(class_distribution.values()))\n",
        "    plt.title('Distribution des classes')\n",
        "    plt.xlabel('Classe')\n",
        "    plt.ylabel('Nombre d\\'images')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Afficher quelques exemples d'images de chaque classe\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, class_idx in enumerate(unique):\n",
        "        # Trouver les indices des images de cette classe\n",
        "        indices = np.where(y == class_idx)[0]\n",
        "        # Sélectionner aléatoirement 5 images (ou moins si moins disponibles)\n",
        "        selected_indices = np.random.choice(indices, min(5, len(indices)), replace=False)\n",
        "        \n",
        "        for j, idx in enumerate(selected_indices):\n",
        "            plt.subplot(len(unique), 5, i*5 + j + 1)\n",
        "            plt.imshow(X[idx])\n",
        "            plt.title(class_names[class_idx])\n",
        "            plt.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_and_explore_data"
      },
      "outputs": [],
      "source": [
        "# Charger et explorer les données\n",
        "X, y, class_weights = load_and_preprocess_data(DATA_DIR, IMG_SIZE)\n",
        "explore_dataset(X, y, CLASS_NAMES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_augmentation"
      },
      "source": [
        "## Augmentation de données et prétraitement\n",
        "\n",
        "Définissons les techniques d'augmentation de données pour améliorer la robustesse du modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "augmentation_functions"
      },
      "outputs": [],
      "source": [
        "def get_train_augmentations(img_size):\n",
        "    \"\"\"\n",
        "    Définit les augmentations de données pour l'entraînement.\n",
        "    \n",
        "    Args:\n",
        "        img_size: Taille cible des images\n",
        "        \n",
        "    Returns:\n",
        "        Transformations d'augmentation pour l'entraînement\n",
        "    \"\"\"\n",
        "    return A.Compose([\n",
        "        A.RandomResizedCrop(height=img_size, width=img_size, scale=(0.8, 1.0)),\n",
        "        A.Flip(p=0.5),\n",
        "        A.RandomRotate90(p=0.5),\n",
        "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "        A.OneOf([\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n",
        "            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20),\n",
        "        ], p=0.5),\n",
        "        A.OneOf([\n",
        "            A.GaussianBlur(blur_limit=3),\n",
        "            A.GaussNoise(var_limit=(10, 50)),\n",
        "            A.MotionBlur(blur_limit=3),\n",
        "        ], p=0.3),\n",
        "        A.CoarseDropout(max_holes=8, max_height=img_size//8, max_width=img_size//8, min_holes=1, p=0.3),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "def get_valid_augmentations(img_size):\n",
        "    \"\"\"\n",
        "    Définit les transformations pour la validation et le test.\n",
        "    \n",
        "    Args:\n",
        "        img_size: Taille cible des images\n",
        "        \n",
        "    Returns:\n",
        "        Transformations pour la validation et le test\n",
        "    \"\"\"\n",
        "    return A.Compose([\n",
        "        A.Resize(height=img_size, width=img_size),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_generator_class"
      },
      "outputs": [],
      "source": [
        "class PlumDataGenerator(tf.keras.utils.Sequence):\n",
        "    \"\"\"\n",
        "    Générateur de données personnalisé pour les images de prunes avec augmentation.\n",
        "    \"\"\"\n",
        "    def __init__(self, images, labels, batch_size, augmentations, shuffle=True):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.augmentations = augmentations\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(self.images))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.images) / self.batch_size))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        batch_indexes = self.indexes[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_images = [self.images[i] for i in batch_indexes]\n",
        "        batch_labels = [self.labels[i] for i in batch_indexes]\n",
        "        \n",
        "        # Appliquer les augmentations\n",
        "        X = np.array([self.augmentations(image=img)[\"image\"] for img in batch_images])\n",
        "        y = tf.keras.utils.to_categorical(batch_labels, num_classes=NUM_CLASSES)\n",
        "        \n",
        "        return X, y\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_architecture"
      },
      "source": [
        "## Architecture du modèle\n",
        "\n",
        "Définissons l'architecture de notre modèle de deep learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_model_function"
      },
      "outputs": [],
      "source": [
        "def create_model(model_name='efficientnet', img_size=224, num_classes=6, dropout_rate=0.3):\n",
        "    \"\"\"\n",
        "    Crée un modèle de deep learning basé sur une architecture pré-entraînée.\n",
        "    \n",
        "    Args:\n",
        "        model_name: Nom de l'architecture de base ('efficientnet', 'resnet', 'xception', 'densenet')\n",
        "        img_size: Taille des images d'entrée\n",
        "        num_classes: Nombre de classes\n",
        "        dropout_rate: Taux de dropout pour la régularisation\n",
        "        \n",
        "    Returns:\n",
        "        Modèle compilé\n",
        "    \"\"\"\n",
        "    # Définir l'entrée\n",
        "    inputs = Input(shape=(img_size, img_size, 3))\n",
        "    \n",
        "    # Sélectionner le modèle de base\n",
        "    if model_name == 'efficientnet':\n",
        "        base_model = EfficientNetB3(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "    elif model_name == 'resnet':\n",
        "        base_model = ResNet50V2(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "    elif model_name == 'xception':\n",
        "        base_model = Xception(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "    elif model_name == 'densenet':\n",
        "        base_model = DenseNet201(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "    else:\n",
        "        raise ValueError(f\"Modèle {model_name} non supporté\")\n",
        "    \n",
        "    # Geler les couches du modèle de base\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # Ajouter des couches personnalisées\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    # Couches denses avec dropout et régularisation\n",
        "    x = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    \n",
        "    x = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    \n",
        "    # Couche de sortie avec activation softmax pour la classification multi-classes\n",
        "    outputs = Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
        "    \n",
        "    # Créer le modèle\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    # Compiler le modèle\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        weight_decay=1e-5\n",
        "    )\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(),\n",
        "            tf.keras.metrics.Recall(),\n",
        "            tfa.metrics.F1Score(num_classes=num_classes, average='macro')\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ensemble_model_function"
      },
      "outputs": [],
      "source": [
        "def create_ensemble_model(models, input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Crée un modèle d'ensemble à partir de plusieurs modèles.\n",
        "    \n",
        "    Args:\n",
        "        models: Liste des modèles à combiner\n",
        "        input_shape: Forme des données d'entrée\n",
        "        num_classes: Nombre de classes\n",
        "        \n",
        "    Returns:\n",
        "        Modèle d'ensemble\n",
        "    \"\"\"\n",
        "    # Créer une entrée commune\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    \n",
        "    # Obtenir les prédictions de chaque modèle\n",
        "    outputs = [model(input_layer) for model in models]\n",
        "    \n",
        "    # Moyenne des prédictions\n",
        "    ensemble_output = layers.Average()(outputs)\n",
        "    \n",
        "    # Créer le modèle d'ensemble\n",
        "    ensemble_model = Model(inputs=input_layer, outputs=ensemble_output)\n",
        "    \n",
        "    # Compiler le modèle\n",
        "    ensemble_model.compile(\n",
        "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            tf.keras.metrics.Precision(),\n",
        "            tf.keras.metrics.Recall(),\n",
        "            tfa.metrics.F1Score(num_classes=num_classes, average='macro')\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    return ensemble_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "advanced_techniques"
      },
      "source": [
        "## Techniques de robustesse avancées\n",
        "\n",
        "Implémentons des techniques avancées pour améliorer la robustesse du modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mixup_cutmix_functions"
      },
      "outputs": [],
      "source": [
        "def apply_mixup(x, y, alpha=0.2):\n",
        "    \"\"\"\n",
        "    Applique la technique de mixup aux données.\n",
        "    \n",
        "    Args:\n",
        "        x: Images\n",
        "        y: Étiquettes (one-hot encoded)\n",
        "        alpha: Paramètre de la distribution beta\n",
        "        \n",
        "    Returns:\n",
        "        Images et étiquettes mixées\n",
        "    \"\"\"\n",
        "    batch_size = tf.shape(x)[0]\n",
        "    indices = tf.random.shuffle(tf.range(batch_size))\n",
        "    \n",
        "    # Générer un lambda à partir d'une distribution beta\n",
        "    lam = tfp.distributions.Beta(alpha, alpha).sample(1)[0]\n",
        "    \n",
        "    # Mélanger les images et les étiquettes\n",
        "    mixed_x = lam * x + (1 - lam) * tf.gather(x, indices)\n",
        "    mixed_y = lam * y + (1 - lam) * tf.gather(y, indices)\n",
        "    \n",
        "    return mixed_x, mixed_y\n",
        "\n",
        "def apply_cutmix(x, y, alpha=1.0):\n",
        "    \"\"\"\n",
        "    Applique la technique de cutmix aux données.\n",
        "    \n",
        "    Args:\n",
        "        x: Images\n",
        "        y: Étiquettes (one-hot encoded)\n",
        "        alpha: Paramètre de la distribution beta\n",
        "        \n",
        "    Returns:\n",
        "        Images et étiquettes mixées\n",
        "    \"\"\"\n",
        "    batch_size = tf.shape(x)[0]\n",
        "    image_height, image_width = x.shape[1], x.shape[2]\n",
        "    indices = tf.random.shuffle(tf.range(batch_size))\n",
        "    \n",
        "    # Générer un lambda à partir d'une distribution beta\n",
        "    lam = tfp.distributions.Beta(alpha, alpha).sample(1)[0]\n",
        "    \n",
        "    # Calculer les dimensions du rectangle à couper\n",
        "    cut_ratio = tf.sqrt(1.0 - lam)\n",
        "    cut_h = tf.cast(image_height * cut_ratio, tf.int32)\n",
        "    cut_w = tf.cast(image_width * cut_ratio, tf.int32)\n",
        "    \n",
        "    # Calculer les coordonnées du rectangle\n",
        "    cx = tf.random.uniform([], 0, image_width, dtype=tf.int32)\n",
        "    cy = tf.random.uniform([], 0, image_height, dtype=tf.int32)\n",
        "    \n",
        "    x1 = tf.clip_by_value(cx - cut_w // 2, 0, image_width)\n",
        "    y1 = tf.clip_by_value(cy - cut_h // 2, 0, image_height)\n",
        "    x2 = tf.clip_by_value(cx + cut_w // 2, 0, image_width)\n",
        "    y2 = tf.clip_by_value(cy + cut_h // 2, 0, image_height)\n",
        "    \n",
        "    # Créer un masque pour le rectangle\n",
        "    mask = tf.ones((batch_size, image_height, image_width, 1))\n",
        "    mask_y1 = tf.repeat(tf.expand_dims(tf.range(0, image_height), 0), batch_size, axis=0)\n",
        "    mask_x1 = tf.repeat(tf.expand_dims(tf.range(0, image_width), 0), batch_size, axis=0)\n",
        "    mask_y1 = tf.expand_dims(mask_y1, -1)\n",
        "    mask_x1 = tf.expand_dims(mask_x1, 2)\n",
        "    \n",
        "    mask = tf.where((mask_y1 >= y1) & (mask_y1 < y2) & (mask_x1 >= x1) & (mask_x1 < x2),\n",
        "                   tf.zeros_like(mask), mask)\n",
        "    \n",
        "    # Appliquer le masque aux images\n",
        "    x1 = x * mask\n",
        "    x2 = tf.gather(x, indices) * (1 - mask)\n",
        "    mixed_x = x1 + x2\n",
        "    \n",
        "    # Calculer le ratio réel de mixage\n",
        "    mixed_area = tf.cast((y2 - y1) * (x2 - x1), tf.float32)\n",
        "    total_area = tf.cast(image_height * image_width, tf.float32)\n",
        "    mix_ratio = 1.0 - (mixed_area / total_area)\n",
        "    \n",
        "    # Mélanger les étiquettes\n",
        "    mixed_y = mix_ratio * y + (1.0 - mix_ratio) * tf.gather(y, indices)\n",
        "    \n",
        "    return mixed_x, mixed_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "robust_data_generator"
      },
      "outputs": [],
      "source": [
        "class RobustPlumDataGenerator(tf.keras.utils.Sequence):\n",
        "    \"\"\"\n",
        "    Générateur de données robuste avec techniques avancées d'augmentation.\n",
        "    \"\"\"\n",
        "    def __init__(self, images, labels, batch_size, augmentations, \n",
        "                 use_mixup=True, use_cutmix=True, mixup_alpha=0.2, cutmix_alpha=1.0,\n",
        "                 shuffle=True):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.augmentations = augmentations\n",
        "        self.use_mixup = use_mixup\n",
        "        self.use_cutmix = use_cutmix\n",
        "        self.mixup_alpha = mixup_alpha\n",
        "        self.cutmix_alpha = cutmix_alpha\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(self.images))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.images) / self.batch_size))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        batch_indexes = self.indexes[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_images = [self.images[i] for i in batch_indexes]\n",
        "        batch_labels = [self.labels[i] for i in batch_indexes]\n",
        "        \n",
        "        # Appliquer les augmentations\n",
        "        X = np.array([self.augmentations(image=img)[\"image\"] for img in batch_images])\n",
        "        y = tf.keras.utils.to_categorical(batch_labels, num_classes=NUM_CLASSES)\n",
        "        \n",
        "        # Appliquer mixup ou cutmix aléatoirement\n",
        "        if self.use_mixup and self.use_cutmix:\n",
        "            if np.random.random() < 0.5:\n",
        "                X, y = apply_mixup(X, y, self.mixup_alpha)\n",
        "            else:\n",
        "                X, y = apply_cutmix(X, y, self.cutmix_alpha)\n",
        "        elif self.use_mixup:\n",
        "            X, y = apply_mixup(X, y, self.mixup_alpha)\n",
        "        elif self.use_cutmix:\n",
        "            X, y = apply_cutmix(X, y, self.cutmix_alpha)\n",
        "        \n",
        "        return X, y\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_section"
      },
      "source": [
        "## Entraînement avec validation croisée\n",
        "\n",
        "Entraînons notre modèle avec validation croisée pour améliorer sa robustesse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cross_validation_function"
      },
      "outputs": [],
      "source": [
        "def train_with_cross_validation(X, y, n_folds=5, model_name='efficientnet', img_size=224, \n",
        "                               batch_size=32, epochs=50, class_weights=None):\n",
        "    \"\"\"\n",
        "    Entraîne le modèle avec validation croisée.\n",
        "    \n",
        "    Args:\n",
        "        X: Images prétraitées\n",
        "        y: Étiquettes correspondantes\n",
        "        n_folds: Nombre de folds pour la validation croisée\n",
        "        model_name: Nom de l'architecture de base\n",
        "        img_size: Taille des images d'entrée\n",
        "        batch_size: Taille des batchs\n",
        "        epochs: Nombre d'époques maximum\n",
        "        class_weights: Poids des classes pour gérer le déséquilibre\n",
        "        \n",
        "    Returns:\n",
        "        Liste des modèles entraînés, scores de validation\n",
        "    \"\"\"\n",
        "    # Préparer la validation croisée stratifiée\n",
        "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
        "    \n",
        "    # Initialiser les listes pour stocker les résultats\n",
        "    fold_models = []\n",
        "    fold_scores = []\n",
        "    \n",
        "    # Transformations d'augmentation\n",
        "    train_aug = get_train_augmentations(img_size)\n",
        "    valid_aug = get_valid_augmentations(img_size)\n",
        "    \n",
        "    # Boucle sur chaque fold\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "        print(f\"\\n{'='*20} Fold {fold+1}/{n_folds} {'='*20}\")\n",
        "        \n",
        "        # Diviser les données\n",
        "        X_train, X_val = X[train_idx], X[val_idx]\n",
        "        y_train, y_val = y[train_idx], y[val_idx]\n",
        "        \n",
        "        # Créer les générateurs de données\n",
        "        train_gen = RobustPlumDataGenerator(X_train, y_train, batch_size, train_aug)\n",
        "        val_gen = PlumDataGenerator(X_val, y_val, batch_size, valid_aug, shuffle=False)\n",
        "        \n",
        "        # Créer et compiler le modèle\n",
        "        model = create_model(model_name=model_name, img_size=img_size, num_classes=NUM_CLASSES)\n",
        "        \n",
        "        # Définir les callbacks\n",
        "        callbacks_list = [\n",
        "            ModelCheckpoint(\n",
        "                filepath=os.path.join(MODELS_DIR, f'model_{model_name}_fold{fold+1}.h5'),\n",
        "                monitor='val_accuracy',\n",
        "                mode='max',\n",
        "                save_best_only=True,\n",
        "                verbose=1\n",
        "            ),\n",
        "            EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=PATIENCE,\n",
        "                restore_best_weights=True,\n",
        "                verbose=1\n",
        "            ),\n",
        "            ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.5,\n",
        "                patience=5,\n",
        "                min_lr=1e-6,\n",
        "                verbose=1\n",
        "            ),\n",
        "            CSVLogger(os.path.join(LOGS_DIR, f'training_log_fold{fold+1}.csv'))\n",
        "        ]\n",
        "        \n",
        "        # Entraîner le modèle\n",
        "        history = model.fit(\n",
        "            train_gen,\n",
        "            validation_data=val_gen,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks_list,\n",
        "            class_weight=class_weights,\n",
        "            verbose=1\n",
        "        )\n",
        "        \n",
        "        # Évaluer le modèle sur le fold de validation\n",
        "        val_loss, val_acc, val_precision, val_recall, val_f1 = model.evaluate(val_gen, verbose=1)\n",
        "        print(f\"Fold {fold+1} - Validation Accuracy: {val_acc:.4f}, F1 Score: {val_f1:.4f}\")\n",
        "        \n",
        "        # Stocker le modèle et les scores\n",
        "        fold_models.append(model)\n",
        "        fold_scores.append({\n",
        "            'val_loss': val_loss,\n",
        "            'val_accuracy': val_acc,\n",
        "            'val_precision': val_precision,\n",
        "            'val_recall': val_recall,\n",
        "            'val_f1': val_f1\n",
        "        })\n",
        "        \n",
        "        # Libérer la mémoire\n",
        "        tf.keras.backend.clear_session()\n",
        "        gc.collect()\n",
        "    \n",
        "    # Calculer et afficher les scores moyens\n",
        "    avg_val_acc = np.mean([score['val_accuracy'] for score in fold_scores])\n",
        "    avg_val_f1 = np.mean([score['val_f1'] for score in fold_scores])\n",
        "    print(f\"\\nValidation croisée terminée - Accuracy moyenne: {avg_val_acc:.4f}, F1 Score moyen: {avg_val_f1:.4f}\")\n",
        "    \n",
        "    return fold_models, fold_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyperparameter_optimization"
      },
      "source": [
        "## Optimisation des hyperparamètres\n",
        "\n",
        "Optimisons les hyperparamètres du modèle pour améliorer ses performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyperparameter_optimization_function"
      },
      "outputs": [],
      "source": [
        "def optimize_hyperparameters(X_train, y_train, X_val, y_val, n_trials=20):\n",
        "    \"\"\"\n",
        "    Optimise les hyperparamètres du modèle avec Optuna.\n",
        "    \n",
        "    Args:\n",
        "        X_train: Images d'entraînement\n",
        "        y_train: Étiquettes d'entraînement\n",
        "        X_val: Images de validation\n",
        "        y_val: Étiquettes de validation\n",
        "        n_trials: Nombre d'essais d'optimisation\n",
        "        \n",
        "    Returns:\n",
        "        Meilleurs hyperparamètres\n",
        "    \"\"\"\n",
        "    import optuna\n",
        "    from optuna.integration import TFKerasPruningCallback\n",
        "    \n",
        "    def objective(trial):\n",
        "        # Hyperparamètres à optimiser\n",
        "        model_name = trial.suggest_categorical('model_name', ['efficientnet', 'resnet', 'xception', 'densenet'])\n",
        "        dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
        "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n",
        "        batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
        "        use_mixup = trial.suggest_categorical('use_mixup', [True, False])\n",
        "        use_cutmix = trial.suggest_categorical('use_cutmix', [True, False])\n",
        "        \n",
        "        # Transformations d'augmentation\n",
        "        train_aug = get_train_augmentations(IMG_SIZE)\n",
        "        valid_aug = get_valid_augmentations(IMG_SIZE)\n",
        "        \n",
        "        # Créer les générateurs de données\n",
        "        train_gen = RobustPlumDataGenerator(\n",
        "            X_train, y_train, batch_size, train_aug,\n",
        "            use_mixup=use_mixup, use_cutmix=use_cutmix\n",
        "        )\n",
        "        val_gen = PlumDataGenerator(X_val, y_val, batch_size, valid_aug, shuffle=False)\n",
        "        \n",
        "        # Créer et compiler le modèle\n",
        "        model = create_model(\n",
        "            model_name=model_name,\n",
        "            img_size=IMG_SIZE,\n",
        "            num_classes=NUM_CLASSES,\n",
        "            dropout_rate=dropout_rate\n",
        "        )\n",
        "        \n",
        "        # Mettre à jour l'optimiseur avec le taux d'apprentissage\n",
        "        optimizer = tfa.optimizers.AdamW(\n",
        "            learning_rate=learning_rate,\n",
        "            weight_decay=1e-5\n",
        "        )\n",
        "        \n",
        "        model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        \n",
        "        # Définir les callbacks\n",
        "        callbacks_list = [\n",
        "            EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=5,\n",
        "                restore_best_weights=True\n",
        "            ),\n",
        "            TFKerasPruningCallback(trial, 'val_accuracy')\n",
        "        ]\n",
        "        \n",
        "        # Entraîner le modèle\n",
        "        history = model.fit(\n",
        "            train_gen,\n",
        "            validation_data=val_gen,\n",
        "            epochs=10,  # Réduire pour l'optimisation\n",
        "            callbacks=callbacks_list,\n",
        "            verbose=0\n",
        "        )\n",
        "        \n",
        "        # Retourner la meilleure précision de validation\n",
        "        return history.history['val_accuracy'][-1]\n",
        "    \n",
        "    # Créer l'étude Optuna\n",
        "    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "    \n",
        "    print(f\"Meilleurs hyperparamètres: {study.best_params}\")\n",
        "    print(f\"Meilleure précision de validation: {study.best_value:.4f}\")\n",
        "    \n",
        "    return study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_section_execution"
      },
      "source": [
        "## Entraînement et évaluation du modèle\n",
        "\n",
        "Entraînons et évaluons notre modèle de deep learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "split_data"
      },
      "outputs": [],
      "source": [
        "# Diviser les données en ensembles d'entraînement, de validation et de test\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X, y, test_size=TEST_SPLIT, stratify=y, random_state=SEED\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=VALIDATION_SPLIT, stratify=y_train_val, random_state=SEED\n",
        ")\n",
        "\n",
        "print(f\"Forme des données d'entraînement: {X_train.shape}\")\n",
        "print(f\"Forme des données de validation: {X_val.shape}\")\n",
        "print(f\"Forme des données de test: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "optimize_hyperparameters"
      },
      "outputs": [],
      "source": [
        "# Optimiser les hyperparamètres (optionnel, peut être commenté pour gagner du temps)\n",
        "best_params = optimize_hyperparameters(X_train, y_train, X_val, y_val, n_trials=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_with_cross_validation"
      },
      "outputs": [],
      "source": [
        "# Entraîner avec validation croisée\n",
        "fold_models, fold_scores = train_with_cross_validation(\n",
        "    X_train_val, y_train_val, n_folds=N_FOLDS,\n",
        "    model_name=best_params.get('model_name', 'efficientnet'),\n",
        "    batch_size=best_params.get('batch_size', BATCH_SIZE),\n",
        "    epochs=EPOCHS, class_weights=class_weights\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_ensemble"
      },
      "outputs": [],
      "source": [
        "# Créer un modèle d'ensemble\n",
        "ensemble_model = create_ensemble_model(\n",
        "    fold_models, (IMG_SIZE, IMG_SIZE, 3), NUM_CLASSES\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evaluation_section"
      },
      "source": [
        "## Évaluation du modèle\n",
        "\n",
        "Évaluons les performances de notre modèle sur l'ensemble de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluate_model_function"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_test, y_test, class_names, batch_size=32):\n",
        "    \"\"\"\n",
        "    Évalue le modèle sur l'ensemble de test.\n",
        "    \n",
        "    Args:\n",
        "        model: Modèle entraîné\n",
        "        X_test: Images de test\n",
        "        y_test: Étiquettes de test\n",
        "        class_names: Noms des classes\n",
        "        batch_size: Taille des batchs\n",
        "        \n",
        "    Returns:\n",
        "        Métriques d'évaluation\n",
        "    \"\"\"\n",
        "    # Préparer les données de test\n",
        "    test_aug = get_valid_augmentations(IMG_SIZE)\n",
        "    test_gen = PlumDataGenerator(X_test, y_test, batch_size, test_aug, shuffle=False)\n",
        "    \n",
        "    # Évaluer le modèle\n",
        "    test_loss, test_acc, test_precision, test_recall, test_f1 = model.evaluate(test_gen, verbose=1)\n",
        "    \n",
        "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"Test Precision: {test_precision:.4f}\")\n",
        "    print(f\"Test Recall: {test_recall:.4f}\")\n",
        "    print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "    \n",
        "    # Prédire les classes\n",
        "    y_pred_proba = model.predict(test_gen)\n",
        "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "    y_true = y_test\n",
        "    \n",
        "    # Rapport de classification\n",
        "    print(\"\\nRapport de classification:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "    \n",
        "    # Matrice de confusion\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Prédictions')\n",
        "    plt.ylabel('Vraies étiquettes')\n",
        "    plt.title('Matrice de confusion')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Visualiser quelques prédictions\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i in range(min(15, len(X_test))):\n",
        "        plt.subplot(3, 5, i+1)\n",
        "        plt.imshow(X_test[i])\n",
        "        true_label = class_names[y_true[i]]\n",
        "        pred_label = class_names[y_pred[i]]\n",
        "        color = 'green' if true_label == pred_label else 'red'\n",
        "        plt.title(f\"Vraie: {true_label}\\nPréd: {pred_label}\", color=color)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return {\n",
        "        'accuracy': test_acc,\n",
        "        'precision': test_precision,\n",
        "        'recall': test_recall,\n",
        "        'f1_score': test_f1,\n",
        "        'confusion_matrix': cm,\n",
        "        'classification_report': classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluate_ensemble"
      },
      "outputs": [],
      "source": [
        "# Évaluer le modèle d'ensemble\n",
        "evaluation_metrics = evaluate_model(ensemble_model, X_test, y_test, CLASS_NAMES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "error_handling_section"
      },
      "source": [
        "## Gestion des erreurs et robustesse\n",
        "\n",
        "Implémentons des mécanismes pour gérer les erreurs et améliorer la robustesse du modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "error_handling_function"
      },
      "outputs": [],
      "source": [
        "def handle_errors_and_edge_cases(model, img_path, class_names, img_size=224):\n",
        "    \"\"\"\n",
        "    Gère les erreurs et les cas limites lors de la prédiction.\n",
        "    \n",
        "    Args:\n",
        "        model: Modèle entraîné\n",
        "        img_path: Chemin vers l'image à prédire\n",
        "        class_names: Noms des classes\n",
        "        img_size: Taille des images d'entrée\n",
        "        \n",
        "    Returns:\n",
        "        Prédiction et score de confiance\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Vérifier si le fichier existe\n",
        "        if not os.path.exists(img_path):\n",
        "            return \"Erreur: Fichier non trouvé\", 0.0\n",
        "        \n",
        "        # Lire l'image\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            return \"Erreur: Impossible de lire l'image\", 0.0\n",
        "        \n",
        "        # Vérifier les dimensions de l'image\n",
        "        if img.shape[0] < 10 or img.shape[1] < 10:\n",
        "            return \"Erreur: Image trop petite\", 0.0\n",
        "        \n",
        "        # Prétraiter l'image\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (img_size, img_size))\n",
        "        \n",
        "        # Normaliser l'image\n",
        "        img = img / 255.0\n",
        "        \n",
        "        # Appliquer les transformations de validation\n",
        "        valid_aug = get_valid_augmentations(img_size)\n",
        "        img_processed = valid_aug(image=img)[\"image\"]\n",
        "        \n",
        "        # Prédire avec le modèle\n",
        "        img_batch = np.expand_dims(img_processed, axis=0)\n",
        "        predictions = model.predict(img_batch)[0]\n",
        "        \n",
        "        # Obtenir la classe prédite et le score de confiance\n",
        "        predicted_class_idx = np.argmax(predictions)\n",
        "        confidence_score = predictions[predicted_class_idx]\n",
        "        \n",
        "        # Vérifier le seuil de confiance\n",
        "        if confidence_score < 0.5:\n",
        "            return \"Incertain: Confiance faible\", confidence_score\n",
        "        \n",
        "        return class_names[predicted_class_idx], confidence_score\n",
        "        \n",
        "    except Exception as e:\n",
        "        return f\"Erreur: {str(e)}\", 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "demo_section"
      },
      "source": [
        "## Interface de démonstration\n",
        "\n",
        "Créons une interface simple pour démontrer notre modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "demo_interface"
      },
      "outputs": [],
      "source": [
        "def create_demo_interface():\n",
        "    \"\"\"\n",
        "    Crée une interface de démonstration simple pour le modèle.\n",
        "    \"\"\"\n",
        "    from IPython.display import display, HTML, clear_output\n",
        "    import ipywidgets as widgets\n",
        "    \n",
        "    # Charger le modèle\n",
        "    try:\n",
        "        model = ensemble_model  # Utiliser le modèle d'ensemble déjà entraîné\n",
        "    except:\n",
        "        print(\"Modèle non trouvé. Veuillez d'abord entraîner le modèle.\")\n",
        "        return\n",
        "    \n",
        "    # Créer les widgets\n",
        "    file_upload = widgets.FileUpload(\n",
        "        accept='.jpg, .jpeg, .png',\n",
        "        multiple=False,\n",
        "        description='Choisir une image'\n",
        "    )\n",
        "    \n",
        "    output = widgets.Output()\n",
        "    \n",
        "    predict_button = widgets.Button(\n",
        "        description='Prédire',\n",
        "        button_style='primary',\n",
        "        disabled=False\n",
        "    )\n",
        "    \n",
        "    # Fonction de prédiction\n",
        "    def on_predict_button_clicked(b):\n",
        "        with output:\n",
        "            clear_output()\n",
        "            \n",
        "            if not file_upload.value:\n",
        "                print(\"Veuillez d'abord télécharger une image.\")\n",
        "                return\n",
        "            \n",
        "            # Récupérer l'image téléchargée\n",
        "            uploaded_file = next(iter(file_upload.value.values()))\n",
        "            content = uploaded_file['content']\n",
        "            \n",
        "            # Sauvegarder l'image temporairement\n",
        "            temp_path = 'temp_image.jpg'\n",
        "            with open(temp_path, 'wb') as f:\n",
        "                f.write(content)\n",
        "            \n",
        "            # Prédire la classe\n",
        "            predicted_class, confidence = handle_errors_and_edge_cases(model, temp_path, CLASS_NAMES, IMG_SIZE)\n",
        "            \n",
        "            # Afficher l'image et la prédiction\n",
        "            img = cv2.imread(temp_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "            plt.figure(figsize=(8, 6))\n",
        "            plt.imshow(img)\n",
        "            plt.title(f\"Prédiction: {predicted_class}\\nConfiance: {confidence:.2f}\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "            \n",
        "            # Supprimer le fichier temporaire\n",
        "            os.remove(temp_path)\n",
        "    \n",
        "    # Associer la fonction au bouton\n",
        "    predict_button.on_click(on_predict_button_clicked)\n",
        "    \n",
        "    # Afficher l'interface\n",
        "    display(HTML(\"<h2>Démonstration du modèle de classification des prunes africaines</h2>\"))\n",
        "    display(HTML(\"<p>Téléchargez une image de prune pour obtenir une prédiction.</p>\"))\n",
        "    display(file_upload)\n",
        "    display(predict_button)\n",
        "    display(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_demo"
      },
      "outputs": [],
      "source": [
        "# Lancer l'interface de démonstration\n",
        "create_demo_interface()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion_section"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Dans ce notebook, nous avons développé un modèle de deep learning robuste pour la classification des prunes africaines en six catégories. Notre approche comprend :\n",
        "\n",
        "1. Une exploration approfondie du dataset\n",
        "2. Des techniques avancées d'augmentation de données\n",
        "3. Une architecture basée sur des modèles pré-entraînés\n",
        "4. Une validation croisée à 5 plis\n",
        "5. Un modèle d'ensemble pour maximiser la précision\n",
        "6. Des mécanismes de gestion d'erreurs pour assurer la robustesse\n",
        "\n",
        "Le modèle final atteint une précision élevée sur l'ensemble de test et est prêt à être utilisé pour le tri automatique des prunes africaines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "save_model_section"
      },
      "source": [
        "## Sauvegarde du modèle final\n",
        "\n",
        "Sauvegardons notre modèle final pour une utilisation ultérieure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save_model"
      },
      "outputs": [],
      "source": [
        "# Sauvegarder le modèle final\n",
        "ensemble_model.save('final_ensemble_model.h5')\n",
        "print(\"Modèle final sauvegardé dans 'final_ensemble_model.h5'\")\n",
        "\n",
        "# Télécharger le modèle\n",
        "from google.colab import files\n",
        "files.download('final_ensemble_model.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
