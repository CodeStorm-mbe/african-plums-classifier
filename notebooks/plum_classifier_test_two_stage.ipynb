{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test du Modèle en Deux Étapes pour la Classification des Prunes Africaines\n",
        "\n",
        "Ce notebook vous permet de tester le modèle en deux étapes pour la classification des prunes africaines. Le modèle fonctionne en deux étapes :\n",
        "1. **Détection** : Détermine si l'image contient une prune ou non\n",
        "2. **Classification** : Si une prune est détectée, détermine son état (bonne qualité, non mûre, tachetée, fissurée, meurtrie ou pourrie)\n",
        "\n",
        "## Étapes :\n",
        "1. Configuration de l'environnement\n",
        "2. Connexion à Google Drive\n",
        "3. Chargement des modèles entraînés\n",
        "4. Téléchargement et test d'images\n",
        "5. Visualisation des résultats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration de l'environnement\n",
        "\n",
        "Commençons par installer les dépendances nécessaires et configurer l'environnement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Installer les dépendances\n",
        "!pip install torch torchvision numpy matplotlib pillow\n",
        "\n",
        "# Importer les bibliothèques nécessaires\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive, files\n",
        "import io\n",
        "import zipfile"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Connexion à Google Drive\n",
        "\n",
        "Connectons-nous à Google Drive pour accéder aux modèles entraînés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Monter Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Définir le chemin vers le dossier contenant les modèles entraînés\n",
        "# Modifiez ce chemin si vos modèles sont stockés ailleurs\n",
        "models_dir = '/content/drive/MyDrive/african_plums_models'\n",
        "\n",
        "# Créer le dossier s'il n'existe pas\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "# Vérifier le contenu du dossier\n",
        "!ls -la {models_dir}"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Téléchargement et configuration du projet\n",
        "\n",
        "Téléchargez le projet corrigé et configurez-le pour l'utilisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Créer les répertoires nécessaires\n",
        "!mkdir -p /content/plum_classifier_corrected/data\n",
        "!mkdir -p /content/plum_classifier_corrected/models\n",
        "!mkdir -p /content/plum_classifier_corrected/scripts\n",
        "\n",
        "# Définir les classes pour la détection et la classification\n",
        "detection_class_names = ['plum', 'non_plum']\n",
        "classification_class_names = ['unaffected', 'unripe', 'spotted', 'cracked', 'bruised', 'rotten']\n",
        "\n",
        "# Créer un fichier model_info.json temporaire\n",
        "model_info = {\n",
        "    \"detection_class_names\": detection_class_names,\n",
        "    \"classification_class_names\": classification_class_names,\n",
        "    \"img_size\": 224,\n",
        "    \"detection_threshold\": 0.7\n",
        "}\n",
        "\n",
        "with open(os.path.join(models_dir, 'two_stage_model_info.json'), 'w') as f:\n",
        "    json.dump(model_info, f, indent=4)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Définition des classes et fonctions nécessaires\n",
        "\n",
        "Définissons les classes et fonctions nécessaires pour le modèle en deux étapes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Définir les transformations pour les images\n",
        "def get_val_transforms(img_size=224):\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "# Fonction pour prétraiter une image\n",
        "def preprocess_single_image(image_path, transform=None):\n",
        "    if transform is None:\n",
        "        transform = get_val_transforms()\n",
        "    \n",
        "    if isinstance(image_path, str):\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "    else:\n",
        "        image = image_path.convert('RGB')\n",
        "        \n",
        "    return transform(image).unsqueeze(0)  # Ajouter une dimension de batch\n",
        "\n",
        "# Définir l'architecture du modèle\n",
        "class PlumClassifier(torch.nn.Module):\n",
        "    \"\"\"Modèle de classification des prunes.\"\"\"\n",
        "    def __init__(self, num_classes=6, base_model='resnet18', pretrained=True, dropout_rate=0.5):\n",
        "        super(PlumClassifier, self).__init__()\n",
        "        \n",
        "        self.base_model_name = base_model\n",
        "        self.num_classes = num_classes\n",
        "        self.dropout_rate = dropout_rate\n",
        "        \n",
        "        # Sélectionner le modèle de base\n",
        "        if base_model == 'resnet18':\n",
        "            from torchvision.models import resnet18\n",
        "            self.base_model = resnet18(pretrained=pretrained)\n",
        "            num_features = self.base_model.fc.in_features\n",
        "            self.base_model.fc = torch.nn.Identity()  # Retirer la dernière couche\n",
        "            \n",
        "        elif base_model == 'resnet50':\n",
        "            from torchvision.models import resnet50\n",
        "            self.base_model = resnet50(pretrained=pretrained)\n",
        "            num_features = self.base_model.fc.in_features\n",
        "            self.base_model.fc = torch.nn.Identity()\n",
        "            \n",
        "        elif base_model == 'mobilenet_v2':\n",
        "            from torchvision.models import mobilenet_v2\n",
        "            self.base_model = mobilenet_v2(pretrained=pretrained)\n",
        "            num_features = self.base_model.classifier[1].in_features\n",
        "            self.base_model.classifier = torch.nn.Identity()\n",
        "        \n",
        "        # Classifier personnalisé avec dropout pour la régularisation\n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Dropout(dropout_rate),\n",
        "            torch.nn.Linear(num_features, 512),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout_rate/2),\n",
        "            torch.nn.Linear(512, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, num_classes)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        features = self.base_model(x)\n",
        "        return self.classifier(features)\n",
        "    \n",
        "    def get_model_info(self):\n",
        "        return {\n",
        "            \"base_model\": self.base_model_name,\n",
        "            \"num_classes\": self.num_classes,\n",
        "            \"dropout_rate\": self.dropout_rate\n",
        "        }\n",
        "\n",
        "class LightweightPlumClassifier(torch.nn.Module):\n",
        "    \"\"\"Version légère du classificateur de prunes.\"\"\"\n",
        "    def __init__(self, num_classes=6, pretrained=True):\n",
        "        super(LightweightPlumClassifier, self).__init__()\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        # Utiliser MobileNetV2 qui est plus léger\n",
        "        from torchvision.models import mobilenet_v2\n",
        "        self.base_model = mobilenet_v2(pretrained=pretrained)\n",
        "        num_features = self.base_model.classifier[1].in_features\n",
        "        self.base_model.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.Linear(num_features, num_classes)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "    \n",
        "    def get_model_info(self):\n",
        "        return {\n",
        "            \"base_model\": \"mobilenet_v2_lightweight\",\n",
        "            \"num_classes\": self.num_classes,\n",
        "            \"dropout_rate\": 0.2\n",
        "        }\n",
        "\n",
        "class TwoStageModel:\n",
        "    \"\"\"Modèle en deux étapes pour la détection et la classification des prunes.\"\"\"\n",
        "    def __init__(self, detection_model, classification_model, detection_threshold=0.7):\n",
        "        self.detection_model = detection_model\n",
        "        self.classification_model = classification_model\n",
        "        self.detection_threshold = detection_threshold\n",
        "        \n",
        "    def predict(self, image_tensor, device):\n",
        "        # Déplacer l'image sur le device\n",
        "        image_tensor = image_tensor.to(device)\n",
        "        \n",
        "        # Étape 1 : Détection de prune\n",
        "        self.detection_model.eval()\n",
        "        with torch.no_grad():\n",
        "            detection_outputs = self.detection_model(image_tensor)\n",
        "            detection_probs = torch.nn.functional.softmax(detection_outputs, dim=1)[0]\n",
        "            \n",
        "            # Classe 0 = prune, Classe 1 = non-prune\n",
        "            is_plum = detection_probs[0] > self.detection_threshold\n",
        "            \n",
        "        # Si ce n'est pas une prune, retourner le résultat\n",
        "        if not is_plum:\n",
        "            return False, \"non_plum\", detection_probs.cpu().numpy()\n",
        "        \n",
        "        # Étape 2 : Classification de l'état de la prune\n",
        "        self.classification_model.eval()\n",
        "        with torch.no_grad():\n",
        "            classification_outputs = self.classification_model(image_tensor)\n",
        "            classification_probs = torch.nn.functional.softmax(classification_outputs, dim=1)[0]\n",
        "            _, predicted_idx = torch.max(classification_outputs, 1)\n",
        "            \n",
        "        return True, predicted_idx.item(), classification_probs.cpu().numpy()\n",
        "    \n",
        "    def get_model_info(self):\n",
        "        detection_info = self.detection_model.get_model_info()\n",
        "        classification_info = self.classification_model.get_model_info()\n",
        "        \n",
        "        return {\n",
        "            \"detection_model\": detection_info,\n",
        "            \"classification_model\": classification_info,\n",
        "            \"detection_threshold\": self.detection_threshold\n",
        "        }\n",
        "\n",
        "def get_model(model_name='standard', num_classes=6, base_model='resnet18', pretrained=True):\n",
        "    \"\"\"Factory function pour créer un modèle.\"\"\"\n",
        "    if model_name == 'standard':\n",
        "        return PlumClassifier(num_classes=num_classes, base_model=base_model, pretrained=pretrained)\n",
        "    elif model_name == 'lightweight':\n",
        "        return LightweightPlumClassifier(num_classes=num_classes, pretrained=pretrained)\n",
        "    else:\n",
        "        raise ValueError(f\"Modèle '{model_name}' non supporté\")\n",
        "\n",
        "def get_two_stage_model(detection_model_name='lightweight', classification_model_name='standard',\n",
        "                       detection_base_model='mobilenet_v2', classification_base_model='resnet18',\n",
        "                       num_detection_classes=2, num_classification_classes=6,\n",
        "                       pretrained=True, detection_threshold=0.7):\n",
        "    \"\"\"Factory function pour créer un modèle en deux étapes.\"\"\"\n",
        "    detection_model = get_model(\n",
        "        model_name=detection_model_name,\n",
        "        num_classes=num_detection_classes,\n",
        "        base_model=detection_base_model,\n",
        "        pretrained=pretrained\n",
        "    )\n",
        "    \n",
        "    classification_model = get_model(\n",
        "        model_name=classification_model_name,\n",
        "        num_classes=num_classification_classes,\n",
        "        base_model=classification_base_model,\n",
        "        pretrained=pretrained\n",
        "    )\n",
        "    \n",
        "    return TwoStageModel(detection_model, classification_model, detection_threshold)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Chargement du modèle en deux étapes\n",
        "\n",
        "Chargeons le modèle en deux étapes à partir des fichiers sauvegardés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "def load_two_stage_model(detection_model_path, classification_model_path, model_info_path, device):\n",
        "    \"\"\"Charge le modèle en deux étapes à partir des fichiers sauvegardés.\"\"\"\n",
        "    # Charger les informations du modèle\n",
        "    with open(model_info_path, 'r') as f:\n",
        "        model_info = json.load(f)\n",
        "    \n",
        "    # Extraire les informations nécessaires\n",
        "    detection_class_names = model_info['detection_class_names']\n",
        "    classification_class_names = model_info['classification_class_names']\n",
        "    detection_threshold = model_info['detection_threshold']\n",
        "    \n",
        "    # Créer le modèle en deux étapes\n",
        "    two_stage_model = get_two_stage_model(\n",
        "        detection_model_name='lightweight',\n",
        "        classification_model_name='standard',\n",
        "        detection_base_model='mobilenet_v2',\n",
        "        classification_base_model='resnet18',\n",
        "        num_detection_classes=len(detection_class_names),\n",
        "        num_classification_classes=len(classification_class_names),\n",
        "        pretrained=False,  # Nous utilisons nos propres poids entraînés\n",
        "        detection_threshold=detection_threshold\n",
        "    )\n",
        "    \n",
        "    # Charger les poids entraînés si les fichiers existent\n",
        "    if os.path.exists(detection_model_path):\n",
        "        two_stage_model.detection_model.load_state_dict(torch.load(detection_model_path, map_location=device))\n",
        "        print(f\"Modèle de détection chargé depuis: {detection_model_path}\")\n",
        "    else:\n",
        "        print(f\"Fichier de modèle de détection non trouvé: {detection_model_path}\")\n",
        "        print(\"Utilisation d'un modèle pré-entraîné pour la détection.\")\n",
        "    \n",
        "    if os.path.exists(classification_model_path):\n",
        "        two_stage_model.classification_model.load_state_dict(torch.load(classification_model_path, map_location=device))\n",
        "        print(f\"Modèle de classification chargé depuis: {classification_model_path}\")\n",
        "    else:\n",
        "        print(f\"Fichier de modèle de classification non trouvé: {classification_model_path}\")\n",
        "        print(\"Utilisation d'un modèle pré-entraîné pour la classification.\")\n",
        "    \n",
        "    # Mettre les modèles en mode évaluation\n",
        "    two_stage_model.detection_model.eval()\n",
        "    two_stage_model.classification_model.eval()\n",
        "    \n",
        "    return two_stage_model, model_info\n",
        "\n",
        "# Déterminer le device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Utilisation de: {device}\")\n",
        "\n",
        "# Chemins vers les fichiers de modèle\n",
        "detection_model_path = os.path.join(models_dir, 'detection_best_acc.pth')\n",
        "classification_model_path = os.path.join(models_dir, 'classification_best_acc.pth')\n",
        "model_info_path = os.path.join(models_dir, 'two_stage_model_info.json')\n",
        "\n",
        "# Charger le modèle en deux étapes\n",
        "print(\"Chargement du modèle en deux étapes...\")\n",
        "model, model_info = load_two_stage_model(\n",
        "    detection_model_path,\n",
        "    classification_model_path,\n",
        "    model_info_path,\n",
        "    device\n",
        ")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Fonction de prédiction et de visualisation\n",
        "\n",
        "Définissons les fonctions pour prédire et visualiser les résultats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "def predict_image(model, image_path, model_info, device, transform=None):\n",
        "    \"\"\"Prédit si l'image contient une prune et, si oui, son état.\"\"\"\n",
        "    # Prétraiter l'image\n",
        "    if transform is None:\n",
        "        img_size = model_info.get('img_size', 224)\n",
        "        transform = get_val_transforms(img_size)\n",
        "    \n",
        "    image_tensor = preprocess_single_image(image_path, transform)\n",
        "    \n",
        "    # Prédiction\n",
        "    is_plum, predicted_idx, probs = model.predict(image_tensor, device)\n",
        "    \n",
        "    if is_plum:\n",
        "        # C'est une prune, retourner la classe prédite\n",
        "        predicted_class = model_info['classification_class_names'][predicted_idx]\n",
        "        return True, predicted_class, None, probs\n",
        "    else:\n",
        "        # Ce n'est pas une prune\n",
        "        return False, \"non_plum\", probs, None\n",
        "\n",
        "def visualize_prediction(image_path, is_plum, predicted_class, detection_probs=None, classification_probs=None, model_info=None):\n",
        "    \"\"\"Visualise l'image avec sa prédiction.\"\"\"\n",
        "    # Charger l'image\n",
        "    if isinstance(image_path, str):\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "    else:\n",
        "        image = image_path.convert('RGB')\n",
        "    \n",
        "    # Créer la figure\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    \n",
        "    # Afficher l'image\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    if is_plum:\n",
        "        plt.title(f\"Prédiction : Prune - {predicted_class}\")\n",
        "    else:\n",
        "        plt.title(\"Prédiction : Pas une prune\")\n",
        "    plt.axis('off')\n",
        "    \n",
        "    # Afficher les probabilités\n",
        "    plt.subplot(1, 2, 2)\n",
        "    \n",
        "    if is_plum and classification_probs is not None and model_info is not None:\n",
        "        # Afficher les probabilités de classification\n",
        "        class_names = model_info['classification_class_names']\n",
        "        y_pos = np.arange(len(class_names))\n",
        "        plt.barh(y_pos, classification_probs, align='center')\n",
        "        plt.yticks(y_pos, class_names)\n",
        "        plt.xlabel('Probabilité')\n",
        "        plt.title('Probabilités par classe')\n",
        "    elif not is_plum and detection_probs is not None and model_info is not None:\n",
        "        # Afficher les probabilités de détection\n",
        "        class_names = model_info['detection_class_names']\n",
        "        y_pos = np.arange(len(class_names))\n",
        "        plt.barh(y_pos, detection_probs, align='center')\n",
        "        plt.yticks(y_pos, class_names)\n",
        "        plt.xlabel('Probabilité')\n",
        "        plt.title('Probabilités de détection')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Afficher les probabilités en pourcentage\n",
        "    print(\"\\nProbabilités détaillées :\")\n",
        "    if is_plum and classification_probs is not None and model_info is not None:\n",
        "        for i, (cls, prob) in enumerate(zip(model_info['classification_class_names'], classification_probs)):\n",
        "            print(f\"{cls}: {prob*100:.2f}%\")\n",
        "    elif not is_plum and detection_probs is not None and model_info is not None:\n",
        "        for i, (cls, prob) in enumerate(zip(model_info['detection_class_names'], detection_probs)):\n",
        "            print(f\"{cls}: {prob*100:.2f}%\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Téléchargement et test d'images\n",
        "\n",
        "Maintenant, vous pouvez télécharger vos propres images et les tester avec le modèle en deux étapes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Fonction pour télécharger et tester une image\n",
        "def upload_and_predict():\n",
        "    print(\"Veuillez télécharger une image :\")\n",
        "    uploaded = files.upload()\n",
        "    \n",
        "    for filename in uploaded.keys():\n",
        "        # Charger l'image\n",
        "        image = Image.open(io.BytesIO(uploaded[filename]))\n",
        "        \n",
        "        # Faire la prédiction\n",
        "        is_plum, predicted_class, detection_probs, classification_probs = predict_image(\n",
        "            model,\n",
        "            image,\n",
        "            model_info,\n",
        "            device\n",
        "        )\n",
        "        \n",
        "        # Afficher les résultats\n",
        "        if is_plum:\n",
        "            print(f\"L'image contient une prune de type: {predicted_class}\")\n",
        "        else:\n",
        "            print(\"L'image ne contient pas de prune.\")\n",
        "        \n",
        "        # Visualiser la prédiction\n",
        "        visualize_prediction(\n",
        "            image,\n",
        "            is_plum,\n",
        "            predicted_class,\n",
        "            detection_probs,\n",
        "            classification_probs,\n",
        "            model_info\n",
        "        )\n",
        "\n",
        "# Exécuter la fonction pour télécharger et tester une image\n",
        "upload_and_predict()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Test avec plusieurs images\n",
        "\n",
        "Vous pouvez également tester plusieurs images à la fois en les téléchargeant depuis votre Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Fonction pour tester des images depuis un dossier\n",
        "def test_images_from_folder(folder_path):\n",
        "    # Vérifier si le dossier existe\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Le dossier {folder_path} n'existe pas.\")\n",
        "        return\n",
        "    \n",
        "    # Récupérer toutes les images du dossier\n",
        "    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
        "    image_files = [f for f in os.listdir(folder_path) \n",
        "                  if os.path.isfile(os.path.join(folder_path, f)) and \n",
        "                  f.lower().endswith(image_extensions)]\n",
        "    \n",
        "    if not image_files:\n",
        "        print(f\"Aucune image trouvée dans {folder_path}.\")\n",
        "        return\n",
        "    \n",
        "    print(f\"Trouvé {len(image_files)} images à tester.\")\n",
        "    \n",
        "    # Tester chaque image\n",
        "    results = []\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        is_plum, predicted_class, detection_probs, classification_probs = predict_image(\n",
        "            model,\n",
        "            image_path,\n",
        "            model_info,\n",
        "            device\n",
        "        )\n",
        "        results.append((image_file, is_plum, predicted_class))\n",
        "    \n",
        "    # Afficher les résultats\n",
        "    num_cols = min(3, len(results))\n",
        "    num_rows = (len(results) + num_cols - 1) // num_cols\n",
        "    \n",
        "    plt.figure(figsize=(15, 5 * num_rows))\n",
        "    \n",
        "    for i, (image_file, is_plum, predicted_class) in enumerate(results):\n",
        "        plt.subplot(num_rows, num_cols, i + 1)\n",
        "        img = Image.open(os.path.join(folder_path, image_file))\n",
        "        plt.imshow(img)\n",
        "        if is_plum:\n",
        "            plt.title(f\"{image_file}\\nPrédiction : Prune - {predicted_class}\")\n",
        "        else:\n",
        "            plt.title(f\"{image_file}\\nPrédiction : Pas une prune\")\n",
        "        plt.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Afficher un tableau récapitulatif\n",
        "    print(\"\\nRécapitulatif des prédictions :\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Image':<20} {'Type':<15} {'Classe prédite':<20}\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    for image_file, is_plum, predicted_class in results:\n",
        "        type_str = \"Prune\" if is_plum else \"Pas une prune\"\n",
        "        print(f\"{image_file[:18]:<20} {type_str:<15} {predicted_class:<20}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Spécifiez le chemin vers un dossier contenant des images dans votre Google Drive\n",
        "test_folder = input(\"Entrez le chemin vers le dossier contenant vos images de test : \")\n",
        "\n",
        "# Tester les images du dossier\n",
        "if test_folder:\n",
        "    test_images_from_folder(test_folder)\n",
        "else:\n",
        "    print(\"Aucun chemin spécifié. Vous pouvez télécharger des images individuelles avec la cellule précédente.\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Télécharger d'autres images pour les tester\n",
        "\n",
        "Vous pouvez continuer à tester d'autres images en exécutant à nouveau la cellule ci-dessous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Exécutez cette cellule pour tester d'autres images\n",
        "upload_and_predict()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Interface simple pour tester plusieurs images\n",
        "\n",
        "Voici une interface simple pour tester plusieurs images à la fois."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Interface simple pour tester plusieurs images\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "def on_upload_button_clicked(b):\n",
        "    clear_output()\n",
        "    display(upload_button)\n",
        "    upload_and_predict()\n",
        "\n",
        "upload_button = widgets.Button(\n",
        "    description='Télécharger et tester une image',\n",
        "    button_style='info',\n",
        "    tooltip='Cliquez pour télécharger une image à tester'\n",
        ")\n",
        "\n",
        "upload_button.on_click(on_upload_button_clicked)\n",
        "display(upload_button)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Résumé et prochaines étapes\n",
        "\n",
        "Félicitations ! Vous avez maintenant un notebook fonctionnel pour tester votre modèle en deux étapes pour la classification des prunes africaines.\n",
        "\n",
        "### Ce que vous avez accompli :\n",
        "- Configuré un modèle en deux étapes qui détecte d'abord si l'image contient une prune, puis classifie son état\n",
        "- Testé des images individuelles téléchargées\n",
        "- Testé des lots d'images depuis un dossier\n",
        "- Visualisé les résultats de prédiction avec les probabilités\n",
        "\n",
        "### Prochaines étapes possibles :\n",
        "- Entraîner le modèle avec vos propres données\n",
        "- Intégrer ce modèle dans une application Django (voir le guide dans le dépôt)\n",
        "- Optimiser davantage le modèle en ajustant les hyperparamètres\n",
        "- Créer une interface utilisateur plus élaborée pour le test\n",
        "- Préparer une présentation pour le hackathon\n",
        "\n",
        "N'hésitez pas à adapter ce notebook à vos besoins spécifiques pour le hackathon JCIA 2025 !"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
