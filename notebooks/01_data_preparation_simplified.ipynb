{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données pour le classificateur de prunes africaines\n",
    "\n",
    "Ce notebook utilise les fonctions existantes dans le dépôt pour préparer les données d'entraînement et de test du modèle de classification des prunes africaines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Ajouter le répertoire parent au chemin pour pouvoir importer nos modules\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Importer nos modules personnalisés\n",
    "from data.data_preprocessing import (\n",
    "    load_and_prepare_data,\n",
    "    load_and_prepare_two_stage_data,\n",
    "    visualize_batch,\n",
    "    analyze_dataset_distribution\n",
    ")\n",
    "\n",
    "# Définir les chemins des données (à modifier selon votre configuration)\n",
    "DATA_ROOT = \"../data/raw\"  # Chemin vers le répertoire de données brutes\n",
    "PLUM_DATA_DIR = os.path.join(DATA_ROOT, \"plums\")  # Sous-dossier pour les prunes\n",
    "NON_PLUM_DATA_DIR = os.path.join(DATA_ROOT, \"non_plums\")  # Sous-dossier pour les non-prunes\n",
    "\n",
    "# Vérifier si les répertoires existent\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "os.makedirs(PLUM_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(NON_PLUM_DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Définir les paramètres\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224\n",
    "NUM_WORKERS = 4\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Fixer les seeds pour la reproductibilité\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Déterminer le device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Utilisation de: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction simple pour explorer les répertoires de données\n",
    "def explore_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Le répertoire {directory} n'existe pas.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Contenu du répertoire {directory}:\")\n",
    "    subdirs = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
    "    print(f\"Sous-dossiers: {subdirs}\")\n",
    "    \n",
    "    for subdir in subdirs:\n",
    "        subdir_path = os.path.join(directory, subdir)\n",
    "        files = [f for f in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, f))]\n",
    "        print(f\"  - {subdir}: {len(files)} fichiers\")\n",
    "\n",
    "# Explorer les répertoires de données\n",
    "print(\"=== Exploration des données de prunes ===\")\n",
    "explore_directory(PLUM_DATA_DIR)\n",
    "\n",
    "print(\"\\n=== Exploration des données non-prunes ===\")\n",
    "explore_directory(NON_PLUM_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyse de la distribution des classes\n",
    "\n",
    "Utilisons la fonction `analyze_dataset_distribution` du module `data_preprocessing` pour analyser la distribution des classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser la distribution des classes\n",
    "try:\n",
    "    print(\"Analyse de la distribution des classes de prunes...\")\n",
    "    class_counts, distribution_img = analyze_dataset_distribution(PLUM_DATA_DIR)\n",
    "    \n",
    "    # Afficher les résultats\n",
    "    print(\"\\nDistribution des classes de prunes:\")\n",
    "    for cls, count in class_counts.items():\n",
    "        print(f\"  - {cls}: {count} images\")\n",
    "    \n",
    "    # Afficher le graphique de distribution\n",
    "    if os.path.exists('class_distribution.png'):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        img = plt.imread('class_distribution.png')\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title('Distribution des classes')\n",
    "        plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de l'analyse de la distribution des classes: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Préparation des données pour le modèle à deux étapes\n",
    "\n",
    "Utilisons la fonction `load_and_prepare_two_stage_data` du module `data_preprocessing` pour préparer les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier si les répertoires de données existent et contiennent des images\n",
    "def check_data_availability():\n",
    "    # Vérifier le répertoire des prunes\n",
    "    plum_classes = [d for d in os.listdir(PLUM_DATA_DIR) if os.path.isdir(os.path.join(PLUM_DATA_DIR, d))]\n",
    "    if not plum_classes:\n",
    "        print(f\"Aucune classe de prune trouvée dans {PLUM_DATA_DIR}. Veuillez ajouter des données.\")\n",
    "        return False\n",
    "    \n",
    "    # Vérifier le répertoire des non-prunes\n",
    "    non_plum_dir = os.path.join(NON_PLUM_DATA_DIR, \"non_plum\")\n",
    "    if not os.path.exists(non_plum_dir):\n",
    "        print(f\"Le répertoire {non_plum_dir} n'existe pas. Veuillez créer ce répertoire et y ajouter des images.\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Vérifier la disponibilité des données\n",
    "data_available = check_data_availability()\n",
    "\n",
    "if data_available:\n",
    "    try:\n",
    "        # Charger et préparer les données pour les deux étapes\n",
    "        print(\"Chargement des données pour les deux étapes...\")\n",
    "        (detection_train_loader, detection_val_loader, detection_test_loader, detection_class_names), \\\n",
    "        (classification_train_loader, classification_val_loader, classification_test_loader, classification_class_names) = \\\n",
    "            load_and_prepare_two_stage_data(\n",
    "                PLUM_DATA_DIR, \n",
    "                NON_PLUM_DATA_DIR,\n",
    "                batch_size=BATCH_SIZE, \n",
    "                img_size=IMG_SIZE,\n",
    "                num_workers=NUM_WORKERS\n",
    "            )\n",
    "        \n",
    "        print(f\"Classes de détection: {detection_class_names}\")\n",
    "        print(f\"Classes de classification: {classification_class_names}\")\n",
    "        \n",
    "        # Afficher les tailles des datasets\n",
    "        print(f\"\\nTailles des datasets de détection:\")\n",
    "        print(f\"  - Entraînement: {len(detection_train_loader.dataset)} images\")\n",
    "        print(f\"  - Validation: {len(detection_val_loader.dataset)} images\")\n",
    "        print(f\"  - Test: {len(detection_test_loader.dataset)} images\")\n",
    "        \n",
    "        print(f\"\\nTailles des datasets de classification:\")\n",
    "        print(f\"  - Entraînement: {len(classification_train_loader.dataset)} images\")\n",
    "        print(f\"  - Validation: {len(classification_val_loader.dataset)} images\")\n",
    "        print(f\"  - Test: {len(classification_test_loader.dataset)} images\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement des données: {e}\")\n",
    "else:\n",
    "    print(\"Veuillez d'abord ajouter des données dans les répertoires appropriés.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisation des données\n",
    "\n",
    "Utilisons la fonction `visualize_batch` du module `data_preprocessing` pour visualiser un batch d'images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser un batch d'images pour chaque étape\n",
    "if data_available and 'detection_train_loader' in locals() and 'classification_train_loader' in locals():\n",
    "    try:\n",
    "        print(\"Visualisation d'un batch d'images pour la détection...\")\n",
    "        detection_batch_viz = visualize_batch(detection_train_loader, detection_class_names)\n",
    "        \n",
    "        print(\"\\nVisualisation d'un batch d'images pour la classification...\")\n",
    "        classification_batch_viz = visualize_batch(classification_train_loader, classification_class_names)\n",
    "        \n",
    "        # Afficher les images sauvegardées\n",
    "        if os.path.exists('batch_visualization.png'):\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            img = plt.imread('batch_visualization.png')\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title('Visualisation du batch')\n",
    "            plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la visualisation des batches: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "Dans ce notebook, nous avons utilisé les fonctions existantes du module `data_preprocessing` pour :\n",
    "1. Explorer les données\n",
    "2. Analyser la distribution des classes\n",
    "3. Préparer les données pour le modèle à deux étapes\n",
    "4. Visualiser les données\n",
    "\n",
    "Les données sont maintenant prêtes pour l'entraînement du modèle dans le notebook suivant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
