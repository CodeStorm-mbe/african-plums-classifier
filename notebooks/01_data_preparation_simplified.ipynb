{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données pour le classificateur de prunes africaines\n",
    "\n",
    "Ce notebook utilise les fonctions existantes dans le dépôt pour préparer les données d'entraînement et de test du modèle de classification des prunes africaines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration de l'environnement pour Google Colab\n",
    "\n",
    "Commençons par cloner le dépôt GitHub et configurer l'environnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier si nous sommes dans Google Colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Exécution dans Google Colab: {IN_COLAB}\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Cloner le dépôt GitHub\n",
    "    !git clone https://github.com/CodeStorm-mbe/african-plums-classifier.git\n",
    "    %cd african-plums-classifier\n",
    "    \n",
    "    # Installer les dépendances requises\n",
    "    !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# Ajouter le répertoire courant au chemin pour pouvoir importer nos modules\n",
    "if IN_COLAB:\n",
    "    # Dans Colab, nous sommes déjà dans le répertoire du projet\n",
    "    if \"/content/african-plums-classifier\" not in sys.path:\n",
    "        sys.path.append(\"/content/african-plums-classifier\")\n",
    "else:\n",
    "    # En local, ajouter le répertoire parent\n",
    "    module_path = os.path.abspath(os.path.join('..'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "# Importer nos modules personnalisés\n",
    "from data.data_preprocessing import (\n",
    "    load_and_prepare_data,\n",
    "    load_and_prepare_two_stage_data,\n",
    "    visualize_batch,\n",
    "    analyze_dataset_distribution\n",
    ")\n",
    "\n",
    "# Définir les chemins des données\n",
    "if IN_COLAB:\n",
    "    # Dans Colab, créer les répertoires dans le dossier du projet cloné\n",
    "    DATA_ROOT = \"data/raw\"\n",
    "else:\n",
    "    # En local\n",
    "    DATA_ROOT = \"../data/raw\"\n",
    "\n",
    "PLUM_DATA_DIR = os.path.join(DATA_ROOT, \"plums\")  # Sous-dossier pour les prunes\n",
    "NON_PLUM_DATA_DIR = os.path.join(DATA_ROOT, \"non_plums\")  # Sous-dossier pour les non-prunes\n",
    "\n",
    "# Vérifier si les répertoires existent\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "os.makedirs(PLUM_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(NON_PLUM_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(NON_PLUM_DATA_DIR, \"non_plum\"), exist_ok=True)\n",
    "\n",
    "# Définir les paramètres\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224\n",
    "NUM_WORKERS = 2 if IN_COLAB else 4  # Réduire le nombre de workers dans Colab\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Fixer les seeds pour la reproductibilité\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Déterminer le device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Utilisation de: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Création de données d'exemple\n",
    "\n",
    "Puisque nous travaillons dans Google Colab sans accès à vos fichiers locaux, créons des données d'exemple pour tester le notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_data(force_create=False):\n",
    "    \"\"\"Crée des données d'exemple pour tester le notebook.\"\"\"\n",
    "    # Vérifier si des données existent déjà\n",
    "    plum_classes = [d for d in os.listdir(PLUM_DATA_DIR) if os.path.isdir(os.path.join(PLUM_DATA_DIR, d))]\n",
    "    non_plum_dir = os.path.join(NON_PLUM_DATA_DIR, \"non_plum\")\n",
    "    \n",
    "    if plum_classes and os.path.exists(non_plum_dir) and not force_create:\n",
    "        print(\"Des données existent déjà. Utilisez force_create=True pour les remplacer.\")\n",
    "        return\n",
    "    \n",
    "    # Créer la structure de dossiers\n",
    "    plum_classes = [\"ripe\", \"unripe\", \"damaged\", \"diseased\", \"overripe\", \"healthy\"]\n",
    "    for cls in plum_classes:\n",
    "        os.makedirs(os.path.join(PLUM_DATA_DIR, cls), exist_ok=True)\n",
    "    \n",
    "    os.makedirs(non_plum_dir, exist_ok=True)\n",
    "    \n",
    "    # Créer des images d'exemple (carrés colorés)\n",
    "    colors = {\n",
    "        \"ripe\": (150, 0, 0),      # Rouge foncé\n",
    "        \"unripe\": (0, 150, 0),    # Vert foncé\n",
    "        \"damaged\": (150, 100, 0), # Marron\n",
    "        \"diseased\": (100, 0, 100),# Violet\n",
    "        \"overripe\": (100, 0, 0),  # Rouge très foncé\n",
    "        \"healthy\": (150, 50, 50)  # Rouge-rose\n",
    "    }\n",
    "    \n",
    "    # Générer des images pour chaque classe de prune\n",
    "    for cls, base_color in colors.items():\n",
    "        for i in range(10):  # 10 images par classe\n",
    "            # Ajouter un peu de variation aléatoire à la couleur\n",
    "            color_var = [max(0, min(255, c + random.randint(-20, 20))) for c in base_color]\n",
    "            \n",
    "            # Créer une image\n",
    "            img = Image.new('RGB', (224, 224), (255, 255, 255))\n",
    "            pixels = img.load()\n",
    "            \n",
    "            # Dessiner un cercle approximatif avec la couleur\n",
    "            center_x, center_y = 112, 112\n",
    "            radius = 100 + random.randint(-10, 10)\n",
    "            \n",
    "            for x in range(img.width):\n",
    "                for y in range(img.height):\n",
    "                    dist = ((x - center_x) ** 2 + (y - center_y) ** 2) ** 0.5\n",
    "                    if dist <= radius:\n",
    "                        # Ajouter du bruit à chaque pixel\n",
    "                        pixel_color = [max(0, min(255, c + random.randint(-10, 10))) for c in color_var]\n",
    "                        pixels[x, y] = tuple(pixel_color)\n",
    "            \n",
    "            # Sauvegarder l'image\n",
    "            img_path = os.path.join(PLUM_DATA_DIR, cls, f\"{cls}_{i+1}.jpg\")\n",
    "            img.save(img_path)\n",
    "    \n",
    "    # Générer des images pour la classe non-prune\n",
    "    for i in range(20):  # 20 images non-prune\n",
    "        # Couleur aléatoire qui n'est pas proche des couleurs de prune\n",
    "        color = (random.randint(0, 100), random.randint(150, 255), random.randint(150, 255))\n",
    "        \n",
    "        # Créer une image\n",
    "        img = Image.new('RGB', (224, 224), (255, 255, 255))\n",
    "        pixels = img.load()\n",
    "        \n",
    "        # Dessiner une forme aléatoire (carré ou triangle)\n",
    "        shape = random.choice(['square', 'triangle'])\n",
    "        \n",
    "        if shape == 'square':\n",
    "            # Dessiner un carré\n",
    "            size = random.randint(100, 150)\n",
    "            top_left = (random.randint(0, 224-size), random.randint(0, 224-size))\n",
    "            \n",
    "            for x in range(top_left[0], top_left[0] + size):\n",
    "                for y in range(top_left[1], top_left[1] + size):\n",
    "                    if 0 <= x < 224 and 0 <= y < 224:\n",
    "                        # Ajouter du bruit à chaque pixel\n",
    "                        pixel_color = [max(0, min(255, c + random.randint(-10, 10))) for c in color]\n",
    "                        pixels[x, y] = tuple(pixel_color)\n",
    "        else:\n",
    "            # Dessiner un triangle\n",
    "            p1 = (random.randint(50, 174), random.randint(50, 174))\n",
    "            p2 = (p1[0] + random.randint(30, 50), p1[1] + random.randint(30, 50))\n",
    "            p3 = (p1[0] - random.randint(0, 30), p2[1])\n",
    "            \n",
    "            # Remplir le triangle (algorithme simple)\n",
    "            min_x = min(p1[0], p2[0], p3[0])\n",
    "            max_x = max(p1[0], p2[0], p3[0])\n",
    "            min_y = min(p1[1], p2[1], p3[1])\n",
    "            max_y = max(p1[1], p2[1], p3[1])\n",
    "            \n",
    "            for x in range(min_x, max_x + 1):\n",
    "                for y in range(min_y, max_y + 1):\n",
    "                    if 0 <= x < 224 and 0 <= y < 224:\n",
    "                        # Vérification simple si le point est dans le triangle\n",
    "                        if (x >= p1[0] and y >= p1[1] and x <= p2[0] and y <= p2[1]):\n",
    "                            # Ajouter du bruit à chaque pixel\n",
    "                            pixel_color = [max(0, min(255, c + random.randint(-10, 10))) for c in color]\n",
    "                            pixels[x, y] = tuple(pixel_color)\n",
    "        \n",
    "        # Sauvegarder l'image\n",
    "        img_path = os.path.join(non_plum_dir, f\"non_plum_{i+1}.jpg\")\n",
    "        img.save(img_path)\n",
    "    \n",
    "    print(f\"Données d'exemple créées avec succès!\")\n",
    "    print(f\"- {len(plum_classes)} classes de prunes avec 10 images chacune\")\n",
    "    print(f\"- 20 images non-prune\")\n",
    "\n",
    "# Créer des données d'exemple\n",
    "create_sample_data(force_create=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction simple pour explorer les répertoires de données\n",
    "def explore_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Le répertoire {directory} n'existe pas.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Contenu du répertoire {directory}:\")\n",
    "    subdirs = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
    "    print(f\"Sous-dossiers: {subdirs}\")\n",
    "    \n",
    "    for subdir in subdirs:\n",
    "        subdir_path = os.path.join(directory, subdir)\n",
    "        files = [f for f in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, f))]\n",
    "        print(f\"  - {subdir}: {len(files)} fichiers\")\n",
    "\n",
    "# Explorer les répertoires de données\n",
    "print(\"=== Exploration des données de prunes ===\")\n",
    "explore_directory(PLUM_DATA_DIR)\n",
    "\n",
    "print(\"\\n=== Exploration des données non-prunes ===\")\n",
    "explore_directory(NON_PLUM_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyse de la distribution des classes\n",
    "\n",
    "Utilisons la fonction `analyze_dataset_distribution` du module `data_preprocessing` pour analyser la distribution des classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser la distribution des classes\n",
    "try:\n",
    "    print(\"Analyse de la distribution des classes de prunes...\")\n",
    "    class_counts, distribution_img = analyze_dataset_distribution(PLUM_DATA_DIR)\n",
    "    \n",
    "    # Afficher les résultats\n",
    "    print(\"\\nDistribution des classes de prunes:\")\n",
    "    for cls, count in class_counts.items():\n",
    "        print(f\"  - {cls}: {count} images\")\n",
    "    \n",
    "    # Afficher le graphique de distribution\n",
    "    if os.path.exists('class_distribution.png'):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        img = plt.imread('class_distribution.png')\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title('Distribution des classes')\n",
    "        plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de l'analyse de la distribution des classes: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Préparation des données pour le modèle à deux étapes\n",
    "\n",
    "Utilisons la fonction `load_and_prepare_two_stage_data` du module `data_preprocessing` pour préparer les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier si les répertoires de données existent et contiennent des images\n",
    "def check_data_availability():\n",
    "    # Vérifier le répertoire des prunes\n",
    "    plum_classes = [d for d in os.listdir(PLUM_DATA_DIR) if os.path.isdir(os.path.join(PLUM_DATA_DIR, d))]\n",
    "    if not plum_classes:\n",
    "        print(f\"Aucune classe de prune trouvée dans {PLUM_DATA_DIR}. Veuillez ajouter des données.\")\n",
    "        return False\n",
    "    \n",
    "    # Vérifier le répertoire des non-prunes\n",
    "    non_plum_dir = os.path.join(NON_PLUM_DATA_DIR, \"non_plum\")\n",
    "    if not os.path.exists(non_plum_dir):\n",
    "        print(f\"Le répertoire {non_plum_dir} n'existe pas. Veuillez créer ce répertoire et y ajouter des images.\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Vérifier la disponibilité des données\n",
    "data_available = check_data_availability()\n",
    "\n",
    "if data_available:\n",
    "    try:\n",
    "        # Charger et préparer les données pour les deux étapes\n",
    "        print(\"Chargement des données pour les deux étapes...\")\n",
    "        (detection_train_loader, detection_val_loader, detection_test_loader, detection_class_names), \\\n",
    "        (classification_train_loader, classification_val_loader, classification_test_loader, classification_class_names) = \\\n",
    "            load_and_prepare_two_stage_data(\n",
    "                PLUM_DATA_DIR, \n",
    "                NON_PLUM_DATA_DIR,\n",
    "                batch_size=BATCH_SIZE, \n",
    "                img_size=IMG_SIZE,\n",
    "                num_workers=NUM_WORKERS\n",
    "            )\n",
    "        \n",
    "        print(f\"Classes de détection: {detection_class_names}\")\n",
    "        print(f\"Classes de classification: {classification_class_names}\")\n",
    "        \n",
    "        # Afficher les tailles des datasets\n",
    "        print(f\"\\nTailles des datasets de détection:\")\n",
    "        print(f\"  - Entraînement: {len(detection_train_loader.dataset)} images\")\n",
    "        print(f\"  - Validation: {len(detection_val_loader.dataset)} images\")\n",
    "        print(f\"  - Test: {len(detection_test_loader.dataset)} images\")\n",
    "        \n",
    "        print(f\"\\nTailles des datasets de classification:\")\n",
    "        print(f\"  - Entraînement: {len(classification_train_loader.dataset)} images\")\n",
    "        print(f\"  - Validation: {len(classification_val_loader.dataset)} images\")\n",
    "        print(f\"  - Test: {len(classification_test_loader.dataset)} images\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement des données: {e}\")\n",
    "else:\n",
    "    print(\"Veuillez d'abord ajouter des données dans les répertoires appropriés.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualisation des données\n",
    "\n",
    "Utilisons la fonction `visualize_batch` du module `data_preprocessing` pour visualiser un batch d'images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser un batch d'images pour chaque étape\n",
    "if data_available and 'detection_train_loader' in locals() and 'classification_train_loader' in locals():\n",
    "    try:\n",
    "        print(\"Visualisation d'un batch d'images pour la détection...\")\n",
    "        detection_batch_viz = visualize_batch(detection_train_loader, detection_class_names)\n",
    "        \n",
    "        print(\"\\nVisualisation d'un batch d'images pour la classification...\")\n",
    "        classification_batch_viz = visualize_batch(classification_train_loader, classification_class_names)\n",
    "        \n",
    "        # Afficher les images sauvegardées\n",
    "        if os.path.exists('batch_visualization.png'):\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            img = plt.imread('batch_visualization.png')\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title('Visualisation du batch')\n",
    "            plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la visualisation des batches: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "Dans ce notebook, nous avons utilisé les fonctions existantes du module `data_preprocessing` pour :\n",
    "1. Explorer les données\n",
    "2. Analyser la distribution des classes\n",
    "3. Préparer les données pour le modèle à deux étapes\n",
    "4. Visualiser les données\n",
    "\n",
    "Les données sont maintenant prêtes pour l'entraînement du modèle dans le notebook suivant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
