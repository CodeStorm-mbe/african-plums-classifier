{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entraînement du Modèle en Deux Étapes pour la Classification des Prunes Africaines\n",
        "\n",
        "Ce notebook vous guide à travers le processus complet d'entraînement du modèle en deux étapes pour la classification des prunes africaines :\n",
        "1. **Détection** : Entraîne un modèle pour déterminer si l'image contient une prune ou non\n",
        "2. **Classification** : Entraîne un modèle pour classifier l'état des prunes (bonne qualité, non mûre, tachetée, fissurée, meurtrie ou pourrie)\n",
        "\n",
        "## Étapes :\n",
        "1. Configuration de l'environnement\n",
        "2. Téléchargement et préparation des données\n",
        "3. Définition de l'architecture du modèle\n",
        "4. Entraînement du modèle de détection\n",
        "5. Entraînement du modèle de classification\n",
        "6. Évaluation des performances\n",
        "7. Sauvegarde des modèles entraînés\n",
        "8. Test du modèle complet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration de l'environnement\n",
        "\n",
        "Commençons par installer les dépendances nécessaires et configurer l'environnement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Vérifier si nous utilisons un GPU\n",
        "!nvidia-smi\n",
        "\n",
        "# Installer les dépendances\n",
        "!pip install torch torchvision numpy matplotlib scikit-learn pillow kaggle seaborn\n",
        "\n",
        "# Importer les bibliothèques nécessaires\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from google.colab import drive, files\n",
        "import zipfile\n",
        "import random\n",
        "\n",
        "# Fixer les seeds pour la reproductibilité\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Déterminer le device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Utilisation de: {device}\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Connexion à Google Drive\n",
        "\n",
        "Connectons-nous à Google Drive pour sauvegarder les modèles entraînés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Monter Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Définir le chemin vers le dossier où sauvegarder les modèles entraînés\n",
        "models_dir = '/content/drive/MyDrive/african_plums_models'\n",
        "\n",
        "# Créer le dossier s'il n'existe pas\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "# Créer un dossier local pour les données\n",
        "data_dir = '/content/data'\n",
        "os.makedirs(data_dir, exist_ok=True)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Téléchargement et préparation des données\n",
        "\n",
        "Pour entraîner notre modèle en deux étapes, nous avons besoin de deux types de données :\n",
        "1. Des images de prunes africaines (dataset Kaggle)\n",
        "2. Des images qui ne sont pas des prunes (pour la détection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Configuration de Kaggle pour télécharger le dataset\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# Télécharger votre fichier kaggle.json depuis votre compte Kaggle et l'importer ici\n",
        "print(\"Veuillez télécharger votre fichier kaggle.json\")\n",
        "files.upload()  # Sélectionnez votre fichier kaggle.json\n",
        "\n",
        "# Déplacer le fichier et définir les permissions\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Télécharger le dataset des prunes africaines\n",
        "!kaggle datasets download -d arnaudfadja/african-plums-quality-and-defect-assessment-data\n",
        "\n",
        "# Extraire le contenu\n",
        "!mkdir -p $data_dir/african_plums_dataset\n",
        "!unzip -q african-plums-quality-and-defect-assessment-data.zip -d $data_dir/african_plums_dataset\n",
        "\n",
        "# Vérifier la structure du dataset\n",
        "!ls -la $data_dir/african_plums_dataset"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Téléchargement d'images qui ne sont pas des prunes\n",
        "\n",
        "Pour la détection, nous avons besoin d'images qui ne sont pas des prunes. Nous allons utiliser un dataset générique d'images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Option 1: Télécharger un dataset d'images diverses depuis Kaggle\n",
        "!kaggle datasets download -d prasunroy/natural-images\n",
        "!mkdir -p $data_dir/non_plum_images\n",
        "!unzip -q natural-images.zip -d $data_dir/temp_natural_images\n",
        "\n",
        "# Copier les images qui ne sont pas des fruits dans le dossier non_plum_images\n",
        "!mkdir -p $data_dir/non_plum_images/non_plum\n",
        "!cp $data_dir/temp_natural_images/natural_images/car/* $data_dir/non_plum_images/non_plum/\n",
        "!cp $data_dir/temp_natural_images/natural_images/cat/* $data_dir/non_plum_images/non_plum/\n",
        "!cp $data_dir/temp_natural_images/natural_images/dog/* $data_dir/non_plum_images/non_plum/\n",
        "!cp $data_dir/temp_natural_images/natural_images/flower/* $data_dir/non_plum_images/non_plum/\n",
        "!cp $data_dir/temp_natural_images/natural_images/house/* $data_dir/non_plum_images/non_plum/\n",
        "!cp $data_dir/temp_natural_images/natural_images/motorbike/* $data_dir/non_plum_images/non_plum/\n",
        "!cp $data_dir/temp_natural_images/natural_images/person/* $data_dir/non_plum_images/non_plum/\n",
        "\n",
        "# Option 2 (alternative): Télécharger vos propres images\n",
        "print(\"\\nVous pouvez également télécharger vos propres images qui ne sont pas des prunes :\")\n",
        "print(\"1. Créez un dossier zip contenant des images qui ne sont pas des prunes\")\n",
        "print(\"2. Téléchargez ce fichier zip ci-dessous\")\n",
        "\n",
        "# Décommenter pour utiliser cette option\n",
        "# uploaded = files.upload()  # Sélectionnez votre fichier zip\n",
        "# for filename in uploaded.keys():\n",
        "#     if filename.endswith('.zip'):\n",
        "#         with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "#             zip_ref.extractall(f'{data_dir}/non_plum_images')\n",
        "\n",
        "# Vérifier le nombre d'images dans chaque dossier\n",
        "!echo \"Nombre d'images de prunes:\"\n",
        "!find $data_dir/african_plums_dataset -type f | wc -l\n",
        "\n",
        "!echo \"Nombre d'images qui ne sont pas des prunes:\"\n",
        "!find $data_dir/non_plum_images -type f | wc -l"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Définition des classes de données et exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Définir les classes pour la détection et la classification\n",
        "detection_class_names = ['plum', 'non_plum']\n",
        "\n",
        "# Trouver les noms des classes de classification à partir des dossiers\n",
        "classification_class_names = [d for d in os.listdir(f'{data_dir}/african_plums_dataset') \n",
        "                             if os.path.isdir(os.path.join(f'{data_dir}/african_plums_dataset', d))]\n",
        "classification_class_names.sort()  # Trier pour avoir un ordre cohérent\n",
        "\n",
        "print(f\"Classes de détection: {detection_class_names}\")\n",
        "print(f\"Classes de classification: {classification_class_names}\")\n",
        "\n",
        "# Explorer la distribution des données\n",
        "def analyze_dataset_distribution(data_dir, class_names):\n",
        "    class_counts = {}\n",
        "    for class_name in class_names:\n",
        "        class_path = os.path.join(data_dir, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            class_counts[class_name] = len(os.listdir(class_path))\n",
        "    \n",
        "    # Afficher la distribution\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(class_counts.keys(), class_counts.values())\n",
        "    plt.xlabel('Classe')\n",
        "    plt.ylabel('Nombre d\\'images')\n",
        "    plt.title('Distribution des classes')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return class_counts\n",
        "\n",
        "# Analyser la distribution des classes de classification\n",
        "print(\"\\nDistribution des classes de classification:\")\n",
        "classification_counts = analyze_dataset_distribution(f'{data_dir}/african_plums_dataset', classification_class_names)\n",
        "\n",
        "# Analyser la distribution des classes de détection\n",
        "print(\"\\nDistribution des classes de détection:\")\n",
        "detection_counts = {}\n",
        "detection_counts['plum'] = sum(classification_counts.values())\n",
        "detection_counts['non_plum'] = len(os.listdir(f'{data_dir}/non_plum_images/non_plum'))\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(detection_counts.keys(), detection_counts.values())\n",
        "plt.xlabel('Classe')\n",
        "plt.ylabel('Nombre d\\'images')\n",
        "plt.title('Distribution des classes de détection')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualisation d'exemples d'images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Visualiser des exemples d'images pour chaque classe\n",
        "def visualize_examples(data_dir, class_names, num_examples=3):\n",
        "    plt.figure(figsize=(15, len(class_names) * 3))\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        class_path = os.path.join(data_dir, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            images = os.listdir(class_path)[:num_examples]  # Prendre 3 exemples\n",
        "            \n",
        "            for j, img_name in enumerate(images):\n",
        "                img_path = os.path.join(class_path, img_name)\n",
        "                img = Image.open(img_path).convert('RGB')\n",
        "                \n",
        "                plt.subplot(len(class_names), num_examples, i*num_examples + j + 1)\n",
        "                plt.imshow(img)\n",
        "                plt.title(f\"{class_name}\")\n",
        "                plt.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualiser des exemples d'images de prunes\n",
        "print(\"Exemples d'images de prunes par classe:\")\n",
        "visualize_examples(f'{data_dir}/african_plums_dataset', classification_class_names)\n",
        "\n",
        "# Visualiser des exemples d'images qui ne sont pas des prunes\n",
        "print(\"\\nExemples d'images qui ne sont pas des prunes:\")\n",
        "visualize_examples(f'{data_dir}/non_plum_images', ['non_plum'], num_examples=5)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Définition des classes et fonctions pour le prétraitement des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Définir les transformations pour les images\n",
        "def get_train_transforms(img_size=224):\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "def get_val_transforms(img_size=224):\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "# Classe de dataset pour les images de prunes\n",
        "class PlumDataset(Dataset):\n",
        "    def __init__(self, root_dir, class_names, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.class_names = class_names\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        \n",
        "        # Collecter les chemins d'images et les labels\n",
        "        for class_idx, class_name in enumerate(class_names):\n",
        "            class_dir = os.path.join(root_dir, class_name)\n",
        "            if os.path.isdir(class_dir):\n",
        "                for img_name in os.listdir(class_dir):\n",
        "                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
        "                        self.image_paths.append(os.path.join(class_dir, img_name))\n",
        "                        self.labels.append(class_idx)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label\n",
        "\n",
        "# Classe de dataset pour les images qui ne sont pas des prunes\n",
        "class NonPlumDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        \n",
        "        # Collecter les chemins d'images\n",
        "        for img_name in os.listdir(root_dir):\n",
        "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
        "                self.image_paths.append(os.path.join(root_dir, img_name))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = 1  # 1 = non_plum\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label\n",
        "\n",
        "# Fonction pour charger et préparer les données pour les deux étapes\n",
        "def load_and_prepare_two_stage_data(plum_data_dir, non_plum_data_dir, batch_size=32, img_size=224, val_split=0.15, test_split=0.15, num_workers=4):\n",
        "    # Transformations\n",
        "    train_transform = get_train_transforms(img_size)\n",
        "    val_transform = get_val_transforms(img_size)\n",
        "    \n",
        "    # 1. Préparer les données pour la détection\n",
        "    # Dataset pour les prunes (classe 0)\n",
        "    plum_dataset = PlumDataset(\n",
        "        root_dir=plum_data_dir,\n",
        "        class_names=classification_class_names,\n",
        "        transform=val_transform  # Utiliser val_transform pour éviter l'augmentation\n",
        "    )\n",
        "    \n",
        "    # Assigner label 0 (plum) à toutes les images de prunes\n",
        "    for i in range(len(plum_dataset.labels)):\n",
        "        plum_dataset.labels[i] = 0\n",
        "    \n",
        "    # Dataset pour les non-prunes (classe 1)\n",
        "    non_plum_dataset = NonPlumDataset(\n",
        "        root_dir=os.path.join(non_plum_data_dir, 'non_plum'),\n",
        "        transform=val_transform  # Utiliser val_transform pour éviter l'augmentation\n",
        "    )\n",
        "    \n",
        "    # Équilibrer les datasets\n",
        "    min_size = min(len(plum_dataset), len(non_plum_dataset))\n",
        "    plum_indices = list(range(len(plum_dataset)))\n",
        "    random.shuffle(plum_indices)\n",
        "    plum_indices = plum_indices[:min_size]\n",
        "    \n",
        "    non_plum_indices = list(range(len(non_plum_dataset)))\n",
        "    random.shuffle(non_plum_indices)\n",
        "    non_plum_indices = non_plum_indices[:min_size]\n",
        "    \n",
        "    # Créer des sous-ensembles équilibrés\n",
        "    from torch.utils.data import Subset\n",
        "    balanced_plum_dataset = Subset(plum_dataset, plum_indices)\n",
        "    balanced_non_plum_dataset = Subset(non_plum_dataset, non_plum_indices)\n",
        "    \n",
        "    # Combiner les datasets pour la détection\n",
        "    from torch.utils.data import ConcatDataset\n",
        "    detection_dataset = ConcatDataset([balanced_plum_dataset, balanced_non_plum_dataset])\n",
        "    \n",
        "    # Diviser en train, val, test\n",
        "    detection_dataset_size = len(detection_dataset)\n",
        "    detection_val_size = int(detection_dataset_size * val_split)\n",
        "    detection_test_size = int(detection_dataset_size * test_split)\n",
        "    detection_train_size = detection_dataset_size - detection_val_size - detection_test_size\n",
        "    \n",
        "    detection_train_dataset, detection_val_dataset, detection_test_dataset = random_split(\n",
        "        detection_dataset, \n",
        "        [detection_train_size, detection_val_size, detection_test_size],\n",
        "        generator=torch.Generator().manual_seed(seed)\n",
        "    )\n",
        "    \n",
        "    # Appliquer les transformations d'entraînement au dataset d'entraînement\n",
        "    detection_train_dataset = TransformDataset(detection_train_dataset, train_transform)\n",
        "    \n",
        "    # Créer les dataloaders pour la détection\n",
        "    detection_train_loader = DataLoader(detection_train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    detection_val_loader = DataLoader(detection_val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "    detection_test_loader = DataLoader(detection_test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "    \n",
        "    # 2. Préparer les données pour la classification\n",
        "    # Dataset pour la classification des prunes\n",
        "    classification_dataset = PlumDataset(\n",
        "        root_dir=plum_data_dir,\n",
        "        class_names=classification_class_names,\n",
        "        transform=val_transform  # Utiliser val_transform pour éviter l'augmentation\n",
        "    )\n",
        "    \n",
        "    # Diviser en train, val, test\n",
        "    classification_dataset_size = len(classification_dataset)\n",
        "    classification_val_size = int(classification_dataset_size * val_split)\n",
        "    classification_test_size = int(classification_dataset_size * test_split)\n",
        "    classification_train_size = classification_dataset_size - classification_val_size - classification_test_size\n",
        "    \n",
        "    classification_train_dataset, classification_val_dataset, classification_test_dataset = random_split(\n",
        "        classification_dataset, \n",
        "        [classification_train_size, classification_val_size, classification_test_size],\n",
        "        generator=torch.Generator().manual_seed(seed)\n",
        "    )\n",
        "    \n",
        "    # Appliquer les transformations d'entraînement au dataset d'entraînement\n",
        "    classification_train_dataset = TransformDataset(classification_train_dataset, train_transform)\n",
        "    \n",
        "    # Créer les dataloaders pour la classification\n",
        "    classification_train_loader = DataLoader(classification_train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    classification_val_loader = DataLoader(classification_val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "    classification_test_loader = DataLoader(classification_test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "    \n",
        "    return (\n",
        "        (detection_train_loader, detection_val_loader, detection_test_loader, detection_class_names),\n",
        "        (classification_train_loader, classification_val_loader, classification_test_loader, classification_class_names)\n",
        "    )\n",
        "\n",
        "# Classe pour appliquer des transformations à un dataset existant\n",
        "class TransformDataset(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.dataset[idx]\n",
        "        \n",
        "        # Si l'image est déjà un tenseur, la convertir en PIL Image\n",
        "        if isinstance(image, torch.Tensor):\n",
        "            # Dénormaliser si nécessaire\n",
        "            if image.shape[0] == 3:  # Si c'est une image RGB\n",
        "                mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "                std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "                image = image * std + mean\n",
        "                image = image.clamp(0, 1)\n",
        "            \n",
        "            # Convertir en PIL Image\n",
        "            image = transforms.ToPILImage()(image)\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label\n",
        "\n",
        "# Fonction pour visualiser un batch d'images\n",
        "def visualize_batch(dataloader, class_names):\n",
        "    # Obtenir un batch\n",
        "    images, labels = next(iter(dataloader))\n",
        "    \n",
        "    # Convertir les images pour l'affichage\n",
        "    images_np = images.numpy()\n",
        "    images_np = np.transpose(images_np, (0, 2, 3, 1))\n",
        "    \n",
        "    # Dénormaliser\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    images_np = images_np * std + mean\n",
        "    images_np = np.clip(images_np, 0, 1)\n",
        "    \n",
        "    # Afficher les images\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    for i in range(min(16, len(images))):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(images_np[i])\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Chargement et préparation des données pour les deux étapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Charger et préparer les données pour les deux étapes\n",
        "print(\"Chargement des données pour les deux étapes...\")\n",
        "(detection_train_loader, detection_val_loader, detection_test_loader, detection_class_names), \\\n",
        "(classification_train_loader, classification_val_loader, classification_test_loader, classification_class_names) = \\\n",
        "    load_and_prepare_two_stage_data(\n",
        "        plum_data_dir=f'{data_dir}/african_plums_dataset', \n",
        "        non_plum_data_dir=f'{data_dir}/non_plum_images',\n",
        "        batch_size=32, \n",
        "        img_size=224,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "print(f\"Classes de détection: {detection_class_names}\")\n",
        "print(f\"Classes de classification: {classification_class_names}\")\n",
        "\n",
        "# Visualiser un batch pour chaque étape\n",
        "print(\"\\nVisualisation d'un batch d'images pour la détection:\")\n",
        "visualize_batch(detection_train_loader, detection_class_names)\n",
        "\n",
        "print(\"\\nVisualisation d'un batch d'images pour la classification:\")\n",
        "visualize_batch(classification_train_loader, classification_class_names)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Définition de l'architecture du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Définir l'architecture du modèle\n",
        "class PlumClassifier(nn.Module):\n",
        "    \"\"\"Modèle de classification des prunes.\"\"\"\n",
        "    def __init__(self, num_classes=6, base_model='resnet18', pretrained=True, dropout_rate=0.5):\n",
        "        super(PlumClassifier, self).__init__()\n",
        "        \n",
        "        self.base_model_name = base_model\n",
        "        self.num_classes = num_classes\n",
        "        self.dropout_rate = dropout_rate\n",
        "        \n",
        "        # Sélectionner le modèle de base\n",
        "        if base_model == 'resnet18':\n",
        "            from torchvision.models import resnet18\n",
        "            self.base_model = resnet18(pretrained=pretrained)\n",
        "            num_features = self.base_model.fc.in_features\n",
        "            self.base_model.fc = nn.Identity()  # Retirer la dernière couche\n",
        "            \n",
        "        elif base_model == 'resnet50':\n",
        "            from torchvision.models import resnet50\n",
        "            self.base_model = resnet50(pretrained=pretrained)\n",
        "            num_features = self.base_model.fc.in_features\n",
        "            self.base_model.fc = nn.Identity()\n",
        "            \n",
        "        elif base_model == 'mobilenet_v2':\n",
        "            from torchvision.models import mobilenet_v2\n",
        "            self.base_model = mobilenet_v2(pretrained=pretrained)\n",
        "            num_features = self.base_model.classifier[1].in_features\n",
        "            self.base_model.classifier = nn.Identity()\n",
        "        \n",
        "        # Classifier personnalisé avec dropout pour la régularisation\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate/2),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        features = self.base_model(x)\n",
        "        return self.classifier(features)\n",
        "    \n",
        "    def get_model_info(self):\n",
        "        return {\n",
        "            \"base_model\": self.base_model_name,\n",
        "            \"num_classes\": self.num_classes,\n",
        "            \"dropout_rate\": self.dropout_rate\n",
        "        }\n",
        "\n",
        "class LightweightPlumClassifier(nn.Module):\n",
        "    \"\"\"Version légère du classificateur de prunes.\"\"\"\n",
        "    def __init__(self, num_classes=6, pretrained=True):\n",
        "        super(LightweightPlumClassifier, self).__init__()\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        # Utiliser MobileNetV2 qui est plus léger\n",
        "        from torchvision.models import mobilenet_v2\n",
        "        self.base_model = mobilenet_v2(pretrained=pretrained)\n",
        "        num_features = self.base_model.classifier[1].in_features\n",
        "        self.base_model.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(num_features, num_classes)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "    \n",
        "    def get_model_info(self):\n",
        "        return {\n",
        "            \"base_model\": \"mobilenet_v2_lightweight\",\n",
        "            \"num_classes\": self.num_classes,\n",
        "            \"dropout_rate\": 0.2\n",
        "        }\n",
        "\n",
        "class TwoStageModel:\n",
        "    \"\"\"Modèle en deux étapes pour la détection et la classification des prunes.\"\"\"\n",
        "    def __init__(self, detection_model, classification_model, detection_threshold=0.7):\n",
        "        self.detection_model = detection_model\n",
        "        self.classification_model = classification_model\n",
        "        self.detection_threshold = detection_threshold\n",
        "        \n",
        "    def predict(self, image_tensor, device):\n",
        "        \"\"\"Prédit si l'image contient une prune et, si oui, son état.\"\"\"\n",
        "        # Déplacer l'image sur le device\n",
        "        image_tensor = image_tensor.to(device)\n",
        "        \n",
        "        # Étape 1 : Détection de prune\n",
        "        self.detection_model.eval()\n",
        "        with torch.no_grad():\n",
        "            detection_outputs = self.detection_model(image_tensor)\n",
        "            detection_probs = torch.nn.functional.softmax(detection_outputs, dim=1)[0]\n",
        "            \n",
        "            # Classe 0 = prune, Classe 1 = non-prune\n",
        "            is_plum = detection_probs[0] > self.detection_threshold\n",
        "            \n",
        "        # Si ce n'est pas une prune, retourner le résultat\n",
        "        if not is_plum:\n",
        "            return False, \"non_plum\", detection_probs.cpu().numpy()\n",
        "        \n",
        "        # Étape 2 : Classification de l'état de la prune\n",
        "        self.classification_model.eval()\n",
        "        with torch.no_grad():\n",
        "            classification_outputs = self.classification_model(image_tensor)\n",
        "            classification_probs = torch.nn.functional.softmax(classification_outputs, dim=1)[0]\n",
        "            _, predicted_idx = torch.max(classification_outputs, 1)\n",
        "            \n",
        "        return True, predicted_idx.item(), classification_probs.cpu().numpy()\n",
        "    \n",
        "    def get_model_info(self):\n",
        "        detection_info = self.detection_model.get_model_info()\n",
        "        classification_info = self.classification_model.get_model_info()\n",
        "        \n",
        "        return {\n",
        "            \"detection_model\": detection_info,\n",
        "            \"classification_model\": classification_info,\n",
        "            \"detection_threshold\": self.detection_threshold\n",
        "        }\n",
        "\n",
        "def get_model(model_name='standard', num_classes=6, base_model='resnet18', pretrained=True):\n",
        "    \"\"\"Factory function pour créer un modèle.\"\"\"\n",
        "    if model_name == 'standard':\n",
        "        return PlumClassifier(num_classes=num_classes, base_model=base_model, pretrained=pretrained)\n",
        "    elif model_name == 'lightweight':\n",
        "        return LightweightPlumClassifier(num_classes=num_classes, pretrained=pretrained)\n",
        "    else:\n",
        "        raise ValueError(f\"Modèle '{model_name}' non supporté\")\n",
        "\n",
        "def get_two_stage_model(detection_model_name='lightweight', classification_model_name='standard',\n",
        "                       detection_base_model='mobilenet_v2', classification_base_model='resnet18',\n",
        "                       num_detection_classes=2, num_classification_classes=6,\n",
        "                       pretrained=True, detection_threshold=0.7):\n",
        "    \"\"\"Factory function pour créer un modèle en deux étapes.\"\"\"\n",
        "    detection_model = get_model(\n",
        "        model_name=detection_model_name,\n",
        "        num_classes=num_detection_classes,\n",
        "        base_model=detection_base_model,\n",
        "        pretrained=pretrained\n",
        "    )\n",
        "    \n",
        "    classification_model = get_model(\n",
        "        model_name=classification_model_name,\n",
        "        num_classes=num_classification_classes,\n",
        "        base_model=classification_base_model,\n",
        "        pretrained=pretrained\n",
        "    )\n",
        "    \n",
        "    return TwoStageModel(detection_model, classification_model, detection_threshold)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Fonctions d'entraînement et d'évaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, \n",
        "                device, num_epochs=25, early_stopping_patience=7, save_dir='models', model_name=\"model\"):\n",
        "    \"\"\"Entraîne le modèle et sauvegarde le meilleur modèle.\"\"\"\n",
        "    # Créer le répertoire de sauvegarde s'il n'existe pas\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    \n",
        "    # Initialiser les variables\n",
        "    best_val_loss = float('inf')\n",
        "    best_val_acc = 0.0\n",
        "    early_stopping_counter = 0\n",
        "    \n",
        "    # Historique pour tracer les courbes\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'train_acc': [],\n",
        "        'val_acc': [],\n",
        "        'lr': []\n",
        "    }\n",
        "    \n",
        "    # Heure de début\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Boucle d'entraînement\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Époque {epoch+1}/{num_epochs}\")\n",
        "        print('-' * 10)\n",
        "        \n",
        "        # Mode entraînement\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        \n",
        "        # Boucle sur les batches d'entraînement\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # Réinitialiser les gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                \n",
        "                # Backward pass et optimisation\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            # Statistiques\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "        \n",
        "        # Calculer les métriques d'entraînement\n",
        "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_train_acc = running_corrects.double() / len(train_loader.dataset)\n",
        "        \n",
        "        # Mode évaluation\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        \n",
        "        # Boucle sur les batches de validation\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # Forward pass\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "            \n",
        "            # Statistiques\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "        \n",
        "        # Calculer les métriques de validation\n",
        "        epoch_val_loss = running_loss / len(val_loader.dataset)\n",
        "        epoch_val_acc = running_corrects.double() / len(val_loader.dataset)\n",
        "        \n",
        "        # Ajuster le learning rate\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        scheduler.step(epoch_val_loss)\n",
        "        \n",
        "        # Afficher les métriques\n",
        "        print(f\"Train Loss: {epoch_train_loss:.4f} Acc: {epoch_train_acc:.4f}\")\n",
        "        print(f\"Val Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc:.4f}\")\n",
        "        print(f\"Learning Rate: {current_lr:.6f}\")\n",
        "        \n",
        "        # Mettre à jour l'historique\n",
        "        history['train_loss'].append(epoch_train_loss)\n",
        "        history['val_loss'].append(epoch_val_loss)\n",
        "        history['train_acc'].append(epoch_train_acc.item())\n",
        "        history['val_acc'].append(epoch_val_acc.item())\n",
        "        history['lr'].append(current_lr)\n",
        "        \n",
        "        # Sauvegarder le meilleur modèle selon la perte de validation\n",
        "        if epoch_val_loss < best_val_loss:\n",
        "            print(f\"Amélioration de la perte de validation de {best_val_loss:.4f} à {epoch_val_loss:.4f}. Sauvegarde du modèle...\")\n",
        "            best_val_loss = epoch_val_loss\n",
        "            torch.save(model.state_dict(), os.path.join(save_dir, f'{model_name}_best_loss.pth'))\n",
        "            early_stopping_counter = 0\n",
        "        else:\n",
        "            early_stopping_counter += 1\n",
        "        \n",
        "        # Sauvegarder le meilleur modèle selon l'accuracy de validation\n",
        "        if epoch_val_acc > best_val_acc:\n",
        "            print(f\"Amélioration de l'accuracy de validation de {best_val_acc:.4f} à {epoch_val_acc:.4f}. Sauvegarde du modèle...\")\n",
        "            best_val_acc = epoch_val_acc\n",
        "            torch.save(model.state_dict(), os.path.join(save_dir, f'{model_name}_best_acc.pth'))\n",
        "        \n",
        "        # Early stopping\n",
        "        if early_stopping_counter >= early_stopping_patience:\n",
        "            print(f\"Early stopping après {early_stopping_counter} époques sans amélioration\")\n",
        "            break\n",
        "        \n",
        "        print()\n",
        "    \n",
        "    # Temps total d'entraînement\n",
        "    time_elapsed = time.time() - start_time\n",
        "    print(f\"Entraînement terminé en {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
        "    print(f\"Meilleure perte de validation: {best_val_loss:.4f}\")\n",
        "    print(f\"Meilleure accuracy de validation: {best_val_acc:.4f}\")\n",
        "    \n",
        "    # Sauvegarder le dernier modèle\n",
        "    torch.save(model.state_dict(), os.path.join(save_dir, f'{model_name}_last.pth'))\n",
        "    \n",
        "    # Sauvegarder l'historique\n",
        "    with open(os.path.join(save_dir, f'{model_name}_history.json'), 'w') as f:\n",
        "        json.dump(history, f)\n",
        "    \n",
        "    return history\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion, device, class_names, save_dir='models', model_name=\"model\"):\n",
        "    \"\"\"Évalue le modèle sur l'ensemble de test et génère des visualisations.\"\"\"\n",
        "    # Créer le répertoire de sauvegarde s'il n'existe pas\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    \n",
        "    # Mode évaluation\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    \n",
        "    # Pour la matrice de confusion\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    # Boucle sur les batches de test\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Statistiques\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        \n",
        "        # Collecter les prédictions et les labels pour la matrice de confusion\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "    \n",
        "    # Calculer les métriques\n",
        "    test_loss = running_loss / len(test_loader.dataset)\n",
        "    test_acc = running_corrects.double() / len(test_loader.dataset)\n",
        "    \n",
        "    print(f\"Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}\")\n",
        "    \n",
        "    # Créer la matrice de confusion\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    \n",
        "    # Visualiser la matrice de confusion\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Prédiction')\n",
        "    plt.ylabel('Vérité')\n",
        "    plt.title('Matrice de confusion')\n",
        "    plt.savefig(os.path.join(save_dir, f'{model_name}_confusion_matrix.png'))\n",
        "    plt.show()\n",
        "    \n",
        "    # Générer le rapport de classification\n",
        "    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
        "    \n",
        "    # Sauvegarder le rapport\n",
        "    with open(os.path.join(save_dir, f'{model_name}_classification_report.json'), 'w') as f:\n",
        "        json.dump(report, f, indent=4)\n",
        "    \n",
        "    # Visualiser les métriques par classe\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    \n",
        "    # Extraire les métriques par classe\n",
        "    classes = list(report.keys())[:-3]  # Exclure 'accuracy', 'macro avg', 'weighted avg'\n",
        "    precision = [report[cls]['precision'] for cls in classes]\n",
        "    recall = [report[cls]['recall'] for cls in classes]\n",
        "    f1 = [report[cls]['f1-score'] for cls in classes]\n",
        "    \n",
        "    # Créer le graphique\n",
        "    x = np.arange(len(classes))\n",
        "    width = 0.25\n",
        "    \n",
        "    plt.bar(x - width, precision, width, label='Precision')\n",
        "    plt.bar(x, recall, width, label='Recall')\n",
        "    plt.bar(x + width, f1, width, label='F1-score')\n",
        "    \n",
        "    plt.xlabel('Classe')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Métriques par classe')\n",
        "    plt.xticks(x, classes, rotation=45)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_dir, f'{model_name}_metrics_by_class.png'))\n",
        "    plt.show()\n",
        "    \n",
        "    return {\n",
        "        'test_loss': test_loss,\n",
        "        'test_acc': test_acc.item(),\n",
        "        'confusion_matrix': cm.tolist(),\n",
        "        'classification_report': report\n",
        "    }\n",
        "\n",
        "def plot_training_history(history, save_dir='models', model_name=\"model\"):\n",
        "    \"\"\"Trace les courbes d'entraînement.\"\"\"\n",
        "    # Créer le répertoire de sauvegarde s'il n'existe pas\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    \n",
        "    # Tracer les courbes de perte\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    \n",
        "    # Graphique des pertes\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['train_loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Époque')\n",
        "    plt.ylabel('Perte')\n",
        "    plt.legend()\n",
        "    plt.title('Évolution des pertes')\n",
        "    \n",
        "    # Graphique de l'accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
        "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
        "    plt.xlabel('Époque')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Évolution de l\\'accuracy')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_dir, f'{model_name}_training_curves.png'))\n",
        "    plt.show()\n",
        "    \n",
        "    # Tracer l'évolution du learning rate\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(history['lr'])\n",
        "    plt.xlabel('Époque')\n",
        "    plt.ylabel('Learning Rate')\n",
        "    plt.title('Évolution du Learning Rate')\n",
        "    plt.yscale('log')\n",
        "    plt.savefig(os.path.join(save_dir, f'{model_name}_learning_rate.png'))\n",
        "    plt.show()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Entraînement du modèle de détection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Étape 1: Entraîner le modèle de détection\n",
        "print(\"\\n=== Entraînement du modèle de détection ===\\n\")\n",
        "\n",
        "# Créer le modèle de détection\n",
        "detection_model = get_model(\n",
        "    model_name='lightweight', \n",
        "    num_classes=len(detection_class_names), \n",
        "    base_model='mobilenet_v2', \n",
        "    pretrained=True\n",
        ")\n",
        "\n",
        "# Déplacer le modèle sur le device\n",
        "detection_model = detection_model.to(device)\n",
        "\n",
        "# Définir la fonction de perte et l'optimiseur\n",
        "detection_criterion = nn.CrossEntropyLoss()\n",
        "detection_optimizer = optim.Adam(detection_model.parameters(), lr=0.001)\n",
        "\n",
        "# Scheduler pour ajuster le learning rate\n",
        "detection_scheduler = ReduceLROnPlateau(detection_optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "# Entraîner le modèle de détection\n",
        "detection_history = train_model(\n",
        "    detection_model, \n",
        "    detection_train_loader, \n",
        "    detection_val_loader, \n",
        "    detection_criterion, \n",
        "    detection_optimizer, \n",
        "    detection_scheduler, \n",
        "    device, \n",
        "    num_epochs=15,  # Réduire pour le notebook\n",
        "    save_dir=models_dir,\n",
        "    model_name=\"detection\"\n",
        ")\n",
        "\n",
        "# Tracer les courbes d'entraînement\n",
        "plot_training_history(detection_history, save_dir=models_dir, model_name=\"detection\")\n",
        "\n",
        "# Charger le meilleur modèle (selon l'accuracy)\n",
        "detection_model.load_state_dict(torch.load(os.path.join(models_dir, 'detection_best_acc.pth')))\n",
        "\n",
        "# Évaluer le modèle de détection\n",
        "detection_metrics = evaluate_model(\n",
        "    detection_model, \n",
        "    detection_test_loader, \n",
        "    detection_criterion, \n",
        "    device, \n",
        "    detection_class_names, \n",
        "    save_dir=models_dir,\n",
        "    model_name=\"detection\"\n",
        ")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Entraînement du modèle de classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Étape 2: Entraîner le modèle de classification\n",
        "print(\"\\n=== Entraînement du modèle de classification ===\\n\")\n",
        "\n",
        "# Créer le modèle de classification\n",
        "classification_model = get_model(\n",
        "    model_name='standard', \n",
        "    num_classes=len(classification_class_names), \n",
        "    base_model='resnet18', \n",
        "    pretrained=True\n",
        ")\n",
        "\n",
        "# Déplacer le modèle sur le device\n",
        "classification_model = classification_model.to(device)\n",
        "\n",
        "# Définir la fonction de perte et l'optimiseur\n",
        "classification_criterion = nn.CrossEntropyLoss()\n",
        "classification_optimizer = optim.Adam(classification_model.parameters(), lr=0.001)\n",
        "\n",
        "# Scheduler pour ajuster le learning rate\n",
        "classification_scheduler = ReduceLROnPlateau(classification_optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "# Entraîner le modèle de classification\n",
        "classification_history = train_model(\n",
        "    classification_model, \n",
        "    classification_train_loader, \n",
        "    classification_val_loader, \n",
        "    classification_criterion, \n",
        "    classification_optimizer, \n",
        "    classification_scheduler, \n",
        "    device, \n",
        "    num_epochs=15,  # Réduire pour le notebook\n",
        "    save_dir=models_dir,\n",
        "    model_name=\"classification\"\n",
        ")\n",
        "\n",
        "# Tracer les courbes d'entraînement\n",
        "plot_training_history(classification_history, save_dir=models_dir, model_name=\"classification\")\n",
        "\n",
        "# Charger le meilleur modèle (selon l'accuracy)\n",
        "classification_model.load_state_dict(torch.load(os.path.join(models_dir, 'classification_best_acc.pth')))\n",
        "\n",
        "# Évaluer le modèle de classification\n",
        "classification_metrics = evaluate_model(\n",
        "    classification_model, \n",
        "    classification_test_loader, \n",
        "    classification_criterion, \n",
        "    device, \n",
        "    classification_class_names, \n",
        "    save_dir=models_dir,\n",
        "    model_name=\"classification\"\n",
        ")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Création du modèle en deux étapes et sauvegarde des informations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Créer le modèle en deux étapes\n",
        "two_stage_model = get_two_stage_model(\n",
        "    detection_model_name='lightweight',\n",
        "    classification_model_name='standard',\n",
        "    detection_base_model='mobilenet_v2',\n",
        "    classification_base_model='resnet18',\n",
        "    num_detection_classes=len(detection_class_names),\n",
        "    num_classification_classes=len(classification_class_names),\n",
        "    pretrained=False,  # Nous utilisons nos propres poids entraînés\n",
        "    detection_threshold=0.7\n",
        ")\n",
        "\n",
        "# Charger les poids entraînés\n",
        "two_stage_model.detection_model.load_state_dict(torch.load(os.path.join(models_dir, 'detection_best_acc.pth')))\n",
        "two_stage_model.classification_model.load_state_dict(torch.load(os.path.join(models_dir, 'classification_best_acc.pth')))\n",
        "\n",
        "# Sauvegarder les informations du modèle\n",
        "model_info = {\n",
        "    \"detection_class_names\": detection_class_names,\n",
        "    \"classification_class_names\": classification_class_names,\n",
        "    \"img_size\": 224,\n",
        "    \"detection_metrics\": detection_metrics,\n",
        "    \"classification_metrics\": classification_metrics,\n",
        "    \"detection_model_info\": two_stage_model.detection_model.get_model_info(),\n",
        "    \"classification_model_info\": two_stage_model.classification_model.get_model_info(),\n",
        "    \"detection_threshold\": two_stage_model.detection_threshold\n",
        "}\n",
        "\n",
        "with open(os.path.join(models_dir, 'two_stage_model_info.json'), 'w') as f:\n",
        "    json.dump(model_info, f, indent=4)\n",
        "\n",
        "print(\"\\n=== Entraînement terminé ===\\n\")\n",
        "print(f\"Modèle en deux étapes entraîné et sauvegardé dans {models_dir}\")\n",
        "print(f\"Métriques de détection: Accuracy={detection_metrics['test_acc']:.4f}\")\n",
        "print(f\"Métriques de classification: Accuracy={classification_metrics['test_acc']:.4f}\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Test du modèle en deux étapes avec des images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Fonction pour prétraiter une image\n",
        "def preprocess_single_image(image_path, transform=None):\n",
        "    if transform is None:\n",
        "        transform = get_val_transforms()\n",
        "    \n",
        "    if isinstance(image_path, str):\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "    else:\n",
        "        image = image_path.convert('RGB')\n",
        "        \n",
        "    return transform(image).unsqueeze(0)  # Ajouter une dimension de batch\n",
        "\n",
        "# Fonction pour prédire une image\n",
        "def predict_image(model, image_path, model_info, device, transform=None):\n",
        "    # Prétraiter l'image\n",
        "    if transform is None:\n",
        "        img_size = model_info.get('img_size', 224)\n",
        "        transform = get_val_transforms(img_size)\n",
        "    \n",
        "    image_tensor = preprocess_single_image(image_path, transform)\n",
        "    \n",
        "    # Prédiction\n",
        "    is_plum, predicted_idx, probs = model.predict(image_tensor, device)\n",
        "    \n",
        "    if is_plum:\n",
        "        # C'est une prune, retourner la classe prédite\n",
        "        predicted_class = model_info['classification_class_names'][predicted_idx]\n",
        "        return True, predicted_class, None, probs\n",
        "    else:\n",
        "        # Ce n'est pas une prune\n",
        "        return False, \"non_plum\", probs, None\n",
        "\n",
        "# Fonction pour visualiser la prédiction\n",
        "def visualize_prediction(image_path, is_plum, predicted_class, detection_probs=None, classification_probs=None, model_info=None):\n",
        "    # Charger l'image\n",
        "    if isinstance(image_path, str):\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "    else:\n",
        "        image = image_path.convert('RGB')\n",
        "    \n",
        "    # Créer la figure\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    \n",
        "    # Afficher l'image\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    if is_plum:\n",
        "        plt.title(f\"Prédiction : Prune - {predicted_class}\")\n",
        "    else:\n",
        "        plt.title(\"Prédiction : Pas une prune\")\n",
        "    plt.axis('off')\n",
        "    \n",
        "    # Afficher les probabilités\n",
        "    plt.subplot(1, 2, 2)\n",
        "    \n",
        "    if is_plum and classification_probs is not None and model_info is not None:\n",
        "        # Afficher les probabilités de classification\n",
        "        class_names = model_info['classification_class_names']\n",
        "        y_pos = np.arange(len(class_names))\n",
        "        plt.barh(y_pos, classification_probs, align='center')\n",
        "        plt.yticks(y_pos, class_names)\n",
        "        plt.xlabel('Probabilité')\n",
        "        plt.title('Probabilités par classe')\n",
        "    elif not is_plum and detection_probs is not None and model_info is not None:\n",
        "        # Afficher les probabilités de détection\n",
        "        class_names = model_info['detection_class_names']\n",
        "        y_pos = np.arange(len(class_names))\n",
        "        plt.barh(y_pos, detection_probs, align='center')\n",
        "        plt.yticks(y_pos, class_names)\n",
        "        plt.xlabel('Probabilité')\n",
        "        plt.title('Probabilités de détection')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Afficher les probabilités en pourcentage\n",
        "    print(\"\\nProbabilités détaillées :\")\n",
        "    if is_plum and classification_probs is not None and model_info is not None:\n",
        "        for i, (cls, prob) in enumerate(zip(model_info['classification_class_names'], classification_probs)):\n",
        "            print(f\"{cls}: {prob*100:.2f}%\")\n",
        "    elif not is_plum and detection_probs is not None and model_info is not None:\n",
        "        for i, (cls, prob) in enumerate(zip(model_info['detection_class_names'], detection_probs)):\n",
        "            print(f\"{cls}: {prob*100:.2f}%\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Tester le modèle avec des images de test\n",
        "print(\"\\n=== Test du modèle en deux étapes ===\\n\")\n",
        "\n",
        "# Sélectionner quelques images de test\n",
        "test_images = []\n",
        "\n",
        "# Ajouter des images de prunes\n",
        "for class_name in classification_class_names:\n",
        "    class_dir = os.path.join(f'{data_dir}/african_plums_dataset', class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
        "        if images:\n",
        "            test_images.append(os.path.join(class_dir, images[0]))\n",
        "\n",
        "# Ajouter des images qui ne sont pas des prunes\n",
        "non_plum_dir = os.path.join(f'{data_dir}/non_plum_images/non_plum')\n",
        "if os.path.isdir(non_plum_dir):\n",
        "    images = [f for f in os.listdir(non_plum_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
        "    if images:\n",
        "        test_images.append(os.path.join(non_plum_dir, images[0]))\n",
        "\n",
        "# Tester chaque image\n",
        "for image_path in test_images:\n",
        "    print(f\"\\nTest de l'image: {os.path.basename(image_path)}\")\n",
        "    \n",
        "    is_plum, predicted_class, detection_probs, classification_probs = predict_image(\n",
        "        two_stage_model,\n",
        "        image_path,\n",
        "        model_info,\n",
        "        device\n",
        "    )\n",
        "    \n",
        "    if is_plum:\n",
        "        print(f\"L'image contient une prune de type: {predicted_class}\")\n",
        "    else:\n",
        "        print(\"L'image ne contient pas de prune.\")\n",
        "    \n",
        "    visualize_prediction(\n",
        "        image_path,\n",
        "        is_plum,\n",
        "        predicted_class,\n",
        "        detection_probs,\n",
        "        classification_probs,\n",
        "        model_info\n",
        "    )"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Téléchargement et test d'images personnalisées"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Fonction pour télécharger et tester une image\n",
        "def upload_and_predict():\n",
        "    print(\"Veuillez télécharger une image :\")\n",
        "    uploaded = files.upload()\n",
        "    \n",
        "    for filename in uploaded.keys():\n",
        "        # Charger l'image\n",
        "        image = Image.open(io.BytesIO(uploaded[filename]))\n",
        "        \n",
        "        # Faire la prédiction\n",
        "        is_plum, predicted_class, detection_probs, classification_probs = predict_image(\n",
        "            two_stage_model,\n",
        "            image,\n",
        "            model_info,\n",
        "            device\n",
        "        )\n",
        "        \n",
        "        # Afficher les résultats\n",
        "        if is_plum:\n",
        "            print(f\"L'image contient une prune de type: {predicted_class}\")\n",
        "        else:\n",
        "            print(\"L'image ne contient pas de prune.\")\n",
        "        \n",
        "        # Visualiser la prédiction\n",
        "        visualize_prediction(\n",
        "            image,\n",
        "            is_plum,\n",
        "            predicted_class,\n",
        "            detection_probs,\n",
        "            classification_probs,\n",
        "            model_info\n",
        "        )\n",
        "\n",
        "# Exécuter la fonction pour télécharger et tester une image\n",
        "upload_and_predict()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Résumé et prochaines étapes\n",
        "\n",
        "Félicitations ! Vous avez maintenant un modèle en deux étapes pour la classification des prunes africaines. Ce modèle peut :\n",
        "1. Détecter si une image contient une prune ou non\n",
        "2. Classifier l'état de la prune si elle est détectée\n",
        "\n",
        "### Ce que vous avez accompli :\n",
        "- Préparé les données pour les deux étapes\n",
        "- Défini l'architecture du modèle en deux étapes\n",
        "- Entraîné les modèles de détection et de classification\n",
        "- Évalué les performances des modèles\n",
        "- Testé le modèle complet avec des images\n",
        "\n",
        "### Prochaines étapes possibles :\n",
        "- Améliorer les performances en ajustant les hyperparamètres\n",
        "- Augmenter le dataset avec plus d'images\n",
        "- Déployer le modèle dans une application Django\n",
        "- Optimiser le modèle pour des appareils mobiles\n",
        "\n",
        "N'hésitez pas à adapter ce notebook à vos besoins spécifiques pour le hackathon JCIA 2025 !"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
