{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test du modèle de classification des prunes africaines\n",
    "\n",
    "Ce notebook utilise les fonctions existantes dans le dépôt pour tester le modèle de classification des prunes africaines en utilisant le jeu de données Kaggle \"African Plums Dataset\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration de l'environnement pour Google Colab\n",
    "\n",
    "Commençons par cloner le dépôt GitHub et configurer l'environnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier si nous sommes dans Google Colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Exécution dans Google Colab: {IN_COLAB}\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Cloner le dépôt GitHub\n",
    "    !git clone https://github.com/CodeStorm-mbe/african-plums-classifier.git\n",
    "    %cd african-plums-classifier\n",
    "    \n",
    "    # Installer les dépendances requises\n",
    "    !pip install -r requirements.txt\n",
    "    !pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration de l'API Kaggle\n",
    "\n",
    "Pour télécharger le jeu de données Kaggle, nous devons configurer l'API Kaggle si ce n'est pas déjà fait dans les notebooks précédents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# Ajouter le répertoire courant au chemin pour pouvoir importer nos modules\n",
    "if IN_COLAB:\n",
    "    # Dans Colab, nous sommes déjà dans le répertoire du projet\n",
    "    if \"/content/african-plums-classifier\" not in sys.path:\n",
    "        sys.path.append(\"/content/african-plums-classifier\")\n",
    "else:\n",
    "    # En local, ajouter le répertoire parent\n",
    "    module_path = os.path.abspath(os.path.join('..'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "# Importer nos modules personnalisés\n",
    "from data.data_preprocessing import preprocess_single_image\n",
    "from models.model_architecture import get_model, TwoStageModel\n",
    "\n",
    "# Définir les chemins\n",
    "if IN_COLAB:\n",
    "    # Dans Colab, créer les répertoires dans le dossier du projet cloné\n",
    "    DATA_ROOT = \"data/raw\"\n",
    "    KAGGLE_DIR = \"data/kaggle\"\n",
    "    MODELS_DIR = \"models/saved\"\n",
    "    TEST_IMAGES_DIR = \"data/test_images\"\n",
    "else:\n",
    "    # En local\n",
    "    DATA_ROOT = \"../data/raw\"\n",
    "    KAGGLE_DIR = \"../data/kaggle\"\n",
    "    MODELS_DIR = \"../models/saved\"\n",
    "    TEST_IMAGES_DIR = \"../data/test_images\"\n",
    "\n",
    "PLUM_DATA_DIR = os.path.join(DATA_ROOT, \"plums\")  # Sous-dossier pour les prunes\n",
    "NON_PLUM_DATA_DIR = os.path.join(DATA_ROOT, \"non_plums\")  # Sous-dossier pour les non-prunes\n",
    "\n",
    "# Créer les répertoires s'ils n'existent pas\n",
    "os.makedirs(PLUM_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(NON_PLUM_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(TEST_IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(KAGGLE_DIR, exist_ok=True)\n",
    "\n",
    "# Définir les paramètres\n",
    "IMG_SIZE = 224\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Fixer les seeds pour la reproductibilité\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Déterminer le device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Utilisation de: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de l'API Kaggle si nécessaire\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    \n",
    "    # Vérifier si le fichier kaggle.json existe déjà\n",
    "    kaggle_config_exists = os.path.exists(os.path.expanduser('~/.kaggle/kaggle.json'))\n",
    "    \n",
    "    if not kaggle_config_exists:\n",
    "        print(\"Veuillez télécharger votre fichier kaggle.json pour l'authentification Kaggle.\")\n",
    "        print(\"Vous pouvez le générer sur https://www.kaggle.com/account dans la section 'API'.\")\n",
    "        \n",
    "        # Télécharger le fichier kaggle.json\n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        # Créer le répertoire .kaggle s'il n'existe pas\n",
    "        os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
    "        \n",
    "        # Déplacer le fichier kaggle.json vers le répertoire .kaggle\n",
    "        if 'kaggle.json' in uploaded:\n",
    "            shutil.move('kaggle.json', os.path.expanduser('~/.kaggle/kaggle.json'))\n",
    "            # Définir les permissions appropriées\n",
    "            os.chmod(os.path.expanduser('~/.kaggle/kaggle.json'), 600)\n",
    "            print(\"Fichier kaggle.json configuré avec succès.\")\n",
    "        else:\n",
    "            print(\"Erreur: Le fichier kaggle.json n'a pas été téléchargé.\")\n",
    "    else:\n",
    "        print(\"Le fichier kaggle.json existe déjà.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Téléchargement des modèles entraînés (pour Google Colab)\n",
    "\n",
    "Si vous êtes dans Google Colab et que vous avez déjà entraîné des modèles, vous pouvez les télécharger ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # Créer une fonction pour télécharger les modèles\n",
    "    def upload_models():\n",
    "        print(\"Veuillez télécharger les fichiers de modèle suivants:\")\n",
    "        print(\"1. detection_best_acc.pth\")\n",
    "        print(\"2. classification_best_acc.pth\")\n",
    "        print(\"3. two_stage_model_info.json\")\n",
    "        \n",
    "        # Télécharger les fichiers\n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        # Déplacer les fichiers vers le répertoire des modèles\n",
    "        for filename in uploaded.keys():\n",
    "            shutil.move(filename, os.path.join(MODELS_DIR, filename))\n",
    "            print(f\"Fichier {filename} déplacé vers {MODELS_DIR}\")\n",
    "    \n",
    "    # Vérifier si les modèles existent déjà\n",
    "    model_files_exist = (\n",
    "        os.path.exists(os.path.join(MODELS_DIR, 'detection_best_acc.pth')) and\n",
    "        os.path.exists(os.path.join(MODELS_DIR, 'classification_best_acc.pth')) and\n",
    "        os.path.exists(os.path.join(MODELS_DIR, 'two_stage_model_info.json'))\n",
    "    )\n",
    "    \n",
    "    if not model_files_exist:\n",
    "        print(\"Les fichiers de modèle n'existent pas. Vous pouvez les télécharger maintenant.\")\n",
    "        # Décommentez la ligne suivante pour télécharger les modèles\n",
    "        # upload_models()\n",
    "    else:\n",
    "        print(\"Les fichiers de modèle existent déjà.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Préparation des images de test à partir du jeu de données Kaggle\n",
    "\n",
    "Téléchargeons et préparons des images de test à partir du jeu de données Kaggle \"African Plums Dataset\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_kaggle_dataset(force_download=False):\n",
    "    \"\"\"Télécharge le jeu de données Kaggle 'African Plums Dataset'.\"\"\"\n",
    "    # Vérifier si le jeu de données a déjà été téléchargé\n",
    "    dataset_zip = os.path.join(KAGGLE_DIR, 'african-plums-dataset.zip')\n",
    "    if os.path.exists(dataset_zip) and not force_download:\n",
    "        print(f\"Le jeu de données a déjà été téléchargé dans {dataset_zip}.\")\n",
    "        return dataset_zip\n",
    "    \n",
    "    print(\"Téléchargement du jeu de données Kaggle 'African Plums Dataset'...\")\n",
    "    try:\n",
    "        # Télécharger le jeu de données\n",
    "        !kaggle datasets download -d arnaudfadja/african-plums-quality-and-defect-assessment-data -p {KAGGLE_DIR}\n",
    "        print(f\"Jeu de données téléchargé avec succès dans {dataset_zip}.\")\n",
    "        return dataset_zip\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du téléchargement du jeu de données: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_and_prepare_test_images(dataset_zip, force_extract=False, num_images_per_class=3):\n",
    "    \"\"\"Extrait et prépare des images de test à partir du jeu de données Kaggle.\"\"\"\n",
    "    if not os.path.exists(dataset_zip):\n",
    "        print(f\"Le fichier {dataset_zip} n'existe pas.\")\n",
    "        return False\n",
    "    \n",
    "    # Vérifier si les données ont déjà été extraites\n",
    "    extracted_dir = os.path.join(KAGGLE_DIR, 'extracted')\n",
    "    if os.path.exists(extracted_dir) and not force_extract:\n",
    "        print(f\"Le jeu de données a déjà été extrait dans {extracted_dir}.\")\n",
    "    else:\n",
    "        print(f\"Extraction du jeu de données...\")\n",
    "        os.makedirs(extracted_dir, exist_ok=True)\n",
    "        \n",
    "        # Extraire le fichier zip\n",
    "        with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extracted_dir)\n",
    "        \n",
    "        print(f\"Jeu de données extrait avec succès dans {extracted_dir}.\")\n",
    "    \n",
    "    # Préparer des images de test\n",
    "    print(\"Préparation des images de test...\")\n",
    "    \n",
    "    # Vérifier la structure du jeu de données extrait\n",
    "    dataset_dir = os.path.join(extracted_dir, 'african_plums_dataset')\n",
    "    if not os.path.exists(dataset_dir):\n",
    "        print(f\"Le répertoire {dataset_dir} n'existe pas.\")\n",
    "        return False\n",
    "    \n",
    "    # Mapper les classes du jeu de données Kaggle\n",
    "    classes = ['bruised', 'cracked', 'rotten', 'spotted', 'unaffected', 'unripe']\n",
    "    \n",
    "    # Sélectionner des images aléatoires pour chaque classe\n",
    "    for cls in classes:\n",
    "        src_dir = os.path.join(dataset_dir, cls)\n",
    "        if not os.path.exists(src_dir):\n",
    "            print(f\"Le répertoire {src_dir} n'existe pas.\")\n",
    "            continue\n",
    "        \n",
    "        # Obtenir la liste des images\n",
    "        images = [f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        if not images:\n",
    "            print(f\"Aucune image trouvée dans {src_dir}.\")\n",
    "            continue\n",
    "        \n",
    "        # Sélectionner des images aléatoires\n",
    "        selected_images = random.sample(images, min(num_images_per_class, len(images)))\n",
    "        \n",
    "        # Copier les images sélectionnées vers le répertoire de test\n",
    "        for i, img_name in enumerate(selected_images):\n",
    "            src_path = os.path.join(src_dir, img_name)\n",
    "            dst_path = os.path.join(TEST_IMAGES_DIR, f\"test_{cls}_{i+1}.jpg\")\n",
    "            shutil.copy(src_path, dst_path)\n",
    "            print(f\"Image copiée: {src_path} -> {dst_path}\")\n",
    "    \n",
    "    # Ajouter des images non-prune (si disponibles)\n",
    "    non_plum_dir = os.path.join(NON_PLUM_DATA_DIR, \"non_plum\")\n",
    "    if os.path.exists(non_plum_dir):\n",
    "        non_plum_images = [f for f in os.listdir(non_plum_dir) if os.path.isfile(os.path.join(non_plum_dir, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        if non_plum_images:\n",
    "            selected_non_plum = random.sample(non_plum_images, min(5, len(non_plum_images)))\n",
    "            for i, img_name in enumerate(selected_non_plum):\n",
    "                src_path = os.path.join(non_plum_dir, img_name)\n",
    "                dst_path = os.path.join(TEST_IMAGES_DIR, f\"test_non_plum_{i+1}.jpg\")\n",
    "                shutil.copy(src_path, dst_path)\n",
    "                print(f\"Image non-prune copiée: {src_path} -> {dst_path}\")\n",
    "    \n",
    "    # Vérifier le nombre d'images de test préparées\n",
    "    test_images = [f for f in os.listdir(TEST_IMAGES_DIR) if os.path.isfile(os.path.join(TEST_IMAGES_DIR, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    print(f\"\\n{len(test_images)} images de test préparées avec succès.\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def prepare_test_images(force_prepare=False, num_images_per_class=3):\n",
    "    \"\"\"Prépare des images de test à partir du jeu de données Kaggle ou crée des images synthétiques.\"\"\"\n",
    "    # Vérifier si des images de test existent déjà\n",
    "    existing_images = [f for f in os.listdir(TEST_IMAGES_DIR) if os.path.isfile(os.path.join(TEST_IMAGES_DIR, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    if existing_images and not force_prepare:\n",
    "        print(f\"Des images de test existent déjà ({len(existing_images)} images). Utilisez force_prepare=True pour les remplacer.\")\n",
    "        return\n",
    "    \n",
    "    # Essayer de télécharger et préparer des images de test à partir du jeu de données Kaggle\n",
    "    try:\n",
    "        dataset_zip = download_kaggle_dataset(force_download=False)\n",
    "        if dataset_zip:\n",
    "            success = extract_and_prepare_test_images(dataset_zip, force_extract=False, num_images_per_class=num_images_per_class)\n",
    "            if success:\n",
    "                print(\"Images de test préparées avec succès à partir du jeu de données Kaggle.\")\n",
    "                return\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la préparation des images de test à partir du jeu de données Kaggle: {e}\")\n",
    "    \n",
    "    # Si le téléchargement ou la préparation échoue, créer des images synthétiques\n",
    "    print(\"Création d'images de test synthétiques...\")\n",
    "    \n",
    "    # Définir les couleurs pour les différentes classes\n",
    "    colors = {\n",
    "        \"ripe\": (150, 0, 0),      # Rouge foncé\n",
    "        \"unripe\": (0, 150, 0),    # Vert foncé\n",
    "        \"damaged\": (150, 100, 0), # Marron\n",
    "        \"diseased\": (100, 0, 100),# Violet\n",
    "        \"overripe\": (100, 0, 0),  # Rouge très foncé\n",
    "        \"healthy\": (150, 50, 50)  # Rouge-rose\n",
    "    }\n",
    "    \n",
    "    # Créer des images pour chaque classe de prune\n",
    "    for cls, base_color in colors.items():\n",
    "        for i in range(3):  # 3 images par classe\n",
    "            # Ajouter un peu de variation aléatoire à la couleur\n",
    "            color_var = [max(0, min(255, c + random.randint(-20, 20))) for c in base_color]\n",
    "            \n",
    "            # Créer une image\n",
    "            img = Image.new('RGB', (224, 224), (255, 255, 255))\n",
    "            pixels = img.load()\n",
    "            \n",
    "            # Dessiner un cercle approximatif avec la couleur\n",
    "            center_x, center_y = 112, 112\n",
    "            radius = 100 + random.randint(-10, 10)\n",
    "            \n",
    "            for x in range(img.width):\n",
    "                for y in range(img.height):\n",
    "                    dist = ((x - center_x) ** 2 + (y - center_y) ** 2) ** 0.5\n",
    "                    if dist <= radius:\n",
    "                        # Ajouter du bruit à chaque pixel\n",
    "                        pixel_color = [max(0, min(255, c + random.randint(-10, 10))) for c in color_var]\n",
    "                        pixels[x, y] = tuple(pixel_color)\n",
    "            \n",
    "            # Sauvegarder l'image\n",
    "            img_path = os.path.join(TEST_IMAGES_DIR, f\"test_{cls}_{i+1}.jpg\")\n",
    "            img.save(img_path)\n",
    "    \n",
    "    # Créer des images non-prune\n",
    "    for i in range(5):  # 5 images non-prune\n",
    "        # Couleur aléatoire qui n'est pas proche des couleurs de prune\n",
    "        color = (random.randint(0, 100), random.randint(150, 255), random.randint(150, 255))\n",
    "        \n",
    "        # Créer une image\n",
    "        img = Image.new('RGB', (224, 224), (255, 255, 255))\n",
    "        pixels = img.load()\n",
    "        \n",
    "        # Dessiner une forme aléatoire (carré ou triangle)\n",
    "        shape = random.choice(['square', 'triangle'])\n",
    "        \n",
    "        if shape == 'square':\n",
    "            # Dessiner un carré\n",
    "            size = random.randint(100, 150)\n",
    "            top_left = (random.randint(0, 224-size), random.randint(0, 224-size))\n",
    "            \n",
    "            for x in range(top_left[0], top_left[0] + size):\n",
    "                for y in range(top_left[1], top_left[1] + size):\n",
    "                    if 0 <= x < 224 and 0 <= y < 224:\n",
    "                        # Ajouter du bruit à chaque pixel\n",
    "                        pixel_color = [max(0, min(255, c + random.randint(-10, 10))) for c in color]\n",
    "                        pixels[x, y] = tuple(pixel_color)\n",
    "        else:\n",
    "            # Dessiner un triangle\n",
    "            p1 = (random.randint(50, 174), random.randint(50, 174))\n",
    "            p2 = (p1[0] + random.randint(30, 50), p1[1] + random.randint(30, 50))\n",
    "            p3 = (p1[0] - random.randint(0, 30), p2[1])\n",
    "            \n",
    "            # Remplir le triangle (algorithme simple)\n",
    "            min_x = min(p1[0], p2[0], p3[0])\n",
    "            max_x = max(p1[0], p2[0], p3[0])\n",
    "            min_y = min(p1[1], p2[1], p3[1])\n",
    "            max_y = max(p1[1], p2[1], p3[1])\n",
    "            \n",
    "            for x in range(min_x, max_x + 1):\n",
    "                for y in range(min_y, max_y + 1):\n",
    "                    if 0 <= x < 224 and 0 <= y < 224:\n",
    "                        # Vérification simple si le point est dans le triangle\n",
    "                        if (x >= p1[0] and y >= p1[1] and x <= p2[0] and y <= p2[1]):\n",
    "                            # Ajouter du bruit à chaque pixel\n",
    "                            pixel_color = [max(0, min(255, c + random.randint(-10, 10))) for c in color]\n",
    "                            pixels[x, y] = tuple(pixel_color)\n",
    "        \n",
    "        # Sauvegarder l'image\n",
    "        img_path = os.path.join(TEST_IMAGES_DIR, f\"test_non_plum_{i+1}.jpg\")\n",
    "        img.save(img_path)\n",
    "    \n",
    "    # Vérifier le nombre d'images de test créées\n",
    "    test_images = [f for f in os.listdir(TEST_IMAGES_DIR) if os.path.isfile(os.path.join(TEST_IMAGES_DIR, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    print(f\"\\n{len(test_images)} images de test synthétiques créées avec succès.\")\n",
    "\n",
    "# Préparer des images de test\n",
    "prepare_test_images(force_prepare=False, num_images_per_class=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisation des images de test\n",
    "\n",
    "Visualisons les images de test que nous avons préparées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_test_images():\n",
    "    \"\"\"Visualise les images de test.\"\"\"\n",
    "    # Obtenir la liste des images de test\n",
    "    test_images = [f for f in os.listdir(TEST_IMAGES_DIR) if os.path.isfile(os.path.join(TEST_IMAGES_DIR, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    if not test_images:\n",
    "        print(\"Aucune image de test trouvée.\")\n",
    "        return\n",
    "    \n",
    "    # Trier les images par classe\n",
    "    test_images.sort()\n",
    "    \n",
    "    # Déterminer le nombre de lignes et de colonnes pour l'affichage\n",
    "    num_images = min(len(test_images), 15)  # Limiter à 15 images pour l'affichage\n",
    "    num_cols = 5\n",
    "    num_rows = (num_images + num_cols - 1) // num_cols\n",
    "    \n",
    "    # Créer la figure\n",
    "    plt.figure(figsize=(15, 3 * num_rows))\n",
    "    \n",
    "    # Afficher chaque image\n",
    "    for i, img_name in enumerate(test_images[:num_images]):\n",
    "        img_path = os.path.join(TEST_IMAGES_DIR, img_name)\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        plt.subplot(num_rows, num_cols, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(img_name.replace('test_', '').replace('.jpg', ''))\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualiser les images de test\n",
    "visualize_test_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Chargement du modèle\n",
    "\n",
    "Chargeons le modèle à deux étapes que nous avons entraîné précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_two_stage_model():\n",
    "    \"\"\"Charge le modèle à deux étapes à partir des fichiers sauvegardés.\"\"\"\n",
    "    # Vérifier si les fichiers nécessaires existent\n",
    "    model_info_path = os.path.join(MODELS_DIR, 'two_stage_model_info.json')\n",
    "    detection_model_path = os.path.join(MODELS_DIR, 'detection_best_acc.pth')\n",
    "    classification_model_path = os.path.join(MODELS_DIR, 'classification_best_acc.pth')\n",
    "    \n",
    "    if not os.path.exists(model_info_path):\n",
    "        raise FileNotFoundError(f\"Le fichier d'informations du modèle n'existe pas: {model_info_path}\")\n",
    "    if not os.path.exists(detection_model_path):\n",
    "        raise FileNotFoundError(f\"Le fichier du modèle de détection n'existe pas: {detection_model_path}\")\n",
    "    if not os.path.exists(classification_model_path):\n",
    "        raise FileNotFoundError(f\"Le fichier du modèle de classification n'existe pas: {classification_model_path}\")\n",
    "    \n",
    "    # Charger les informations du modèle\n",
    "    with open(model_info_path, 'r') as f:\n",
    "        model_info = json.load(f)\n",
    "    \n",
    "    # Extraire les informations\n",
    "    detection_classes = model_info['detection_classes']\n",
    "    classification_classes = model_info['classification_classes']\n",
    "    model_architecture_info = model_info['model_info']\n",
    "    \n",
    "    # Créer les modèles\n",
    "    detection_model = get_model(\n",
    "        model_name=model_architecture_info['detection_model']['base_model'].split('_')[0] if '_' in model_architecture_info['detection_model']['base_model'] else 'standard',\n",
    "        num_classes=len(detection_classes),\n",
    "        base_model=model_architecture_info['detection_model']['base_model'].split('_')[1] if '_' in model_architecture_info['detection_model']['base_model'] else model_architecture_info['detection_model']['base_model'],\n",
    "        pretrained=False\n",
    "    )\n",
    "    \n",
    "    classification_model = get_model(\n",
    "        model_name=model_architecture_info['classification_model']['base_model'].split('_')[0] if '_' in model_architecture_info['classification_model']['base_model'] else 'standard',\n",
    "        num_classes=len(classification_classes),\n",
    "        base_model=model_architecture_info['classification_model']['base_model'].split('_')[1] if '_' in model_architecture_info['classification_model']['base_model'] else model_architecture_info['classification_model']['base_model'],\n",
    "        pretrained=False\n",
    "    )\n",
    "    \n",
    "    # Charger les poids\n",
    "    detection_model.load_state_dict(torch.load(detection_model_path, map_location=device))\n",
    "    classification_model.load_state_dict(torch.load(classification_model_path, map_location=device))\n",
    "    \n",
    "    # Créer le modèle à deux étapes\n",
    "    two_stage_model = TwoStageModel(\n",
    "        detection_model, \n",
    "        classification_model, \n",
    "        detection_threshold=model_architecture_info['detection_threshold'] if 'detection_threshold' in model_architecture_info else 0.7\n",
    "    )\n",
    "    \n",
    "    return two_stage_model, detection_classes, classification_classes\n",
    "\n",
    "# Charger le modèle\n",
    "try:\n",
    "    model, detection_classes, classification_classes = load_two_stage_model()\n",
    "    model.detection_model.to(device)\n",
    "    model.classification_model.to(device)\n",
    "    \n",
    "    print(\"Modèle à deux étapes chargé avec succès!\")\n",
    "    print(f\"Classes de détection: {detection_classes}\")\n",
    "    print(f\"Classes de classification: {classification_classes}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement du modèle: {e}\")\n",
    "    print(\"\\nSi vous n'avez pas encore entraîné le modèle, veuillez d'abord exécuter le notebook d'entraînement.\")\n",
    "    \n",
    "    # Créer des classes fictives pour pouvoir continuer le notebook\n",
    "    detection_classes = ['plum', 'non_plum']\n",
    "    classification_classes = ['bruised', 'cracked', 'rotten', 'spotted', 'unaffected', 'unripe']\n",
    "    print(\"\\nUtilisation de classes fictives pour la démonstration:\")\n",
    "    print(f\"Classes de détection: {detection_classes}\")\n",
    "    print(f\"Classes de classification: {classification_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prédiction sur une image individuelle\n",
    "\n",
    "Testons notre modèle sur une image individuelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(model, img_path, detection_classes, classification_classes):\n",
    "    \"\"\"Prédit la classe d'une image individuelle.\"\"\"\n",
    "    # Vérifier si le fichier existe\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Le fichier {img_path} n'existe pas.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Charger et prétraiter l'image\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_tensor = preprocess_single_image(img, IMG_SIZE)\n",
    "    img_tensor = img_tensor.unsqueeze(0).to(device)  # Ajouter la dimension du batch\n",
    "    \n",
    "    # Passer en mode évaluation\n",
    "    model.detection_model.eval()\n",
    "    model.classification_model.eval()\n",
    "    \n",
    "    # Prédire\n",
    "    with torch.no_grad():\n",
    "        # Prédiction de détection\n",
    "        detection_output = model.detection_model(img_tensor)\n",
    "        detection_probs = torch.nn.functional.softmax(detection_output, dim=1)\n",
    "        detection_pred = torch.argmax(detection_probs, dim=1).item()\n",
    "        detection_prob = detection_probs[0, detection_pred].item()\n",
    "        \n",
    "        # Si c'est une prune, prédire la classe\n",
    "        if detection_classes[detection_pred] == 'plum' and detection_prob >= model.detection_threshold:\n",
    "            # Prédiction de classification\n",
    "            classification_output = model.classification_model(img_tensor)\n",
    "            classification_probs = torch.nn.functional.softmax(classification_output, dim=1)\n",
    "            classification_pred = torch.argmax(classification_probs, dim=1).item()\n",
    "            classification_prob = classification_probs[0, classification_pred].item()\n",
    "            \n",
    "            return detection_classes[detection_pred], classification_classes[classification_pred], {\n",
    "                'detection_prob': detection_prob,\n",
    "                'classification_prob': classification_prob,\n",
    "                'detection_probs': detection_probs.cpu().numpy()[0],\n",
    "                'classification_probs': classification_probs.cpu().numpy()[0]\n",
    "            }\n",
    "        else:\n",
    "            return detection_classes[detection_pred], None, {\n",
    "                'detection_prob': detection_prob,\n",
    "                'detection_probs': detection_probs.cpu().numpy()[0]\n",
    "            }\n",
    "\n",
    "def visualize_prediction(img_path, detection_pred, classification_pred, probs):\n",
    "    \"\"\"Visualise l'image avec sa prédiction.\"\"\"\n",
    "    # Charger l'image\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    \n",
    "    # Créer la figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Afficher l'image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Image de test\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Afficher les prédictions\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Texte de prédiction\n",
    "    text = f\"Détection: {detection_pred} ({probs['detection_prob']:.2f})\\n\"\n",
    "    if classification_pred is not None:\n",
    "        text += f\"Classification: {classification_pred} ({probs['classification_prob']:.2f})\"\n",
    "    else:\n",
    "        text += \"Classification: N/A\"\n",
    "    \n",
    "    plt.text(0.1, 0.5, text, fontsize=12)\n",
    "    \n",
    "    # Afficher les probabilités de détection\n",
    "    if 'detection_probs' in probs:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.bar(detection_classes, probs['detection_probs'])\n",
    "        plt.title(\"Probabilités de détection\")\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # Afficher les probabilités de classification si disponibles\n",
    "        if 'classification_probs' in probs:\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.bar(classification_classes, probs['classification_probs'])\n",
    "            plt.title(\"Probabilités de classification\")\n",
    "            plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Tester le modèle sur une image individuelle\n",
    "if 'model' in locals():\n",
    "    # Obtenir la liste des images de test\n",
    "    test_images = [f for f in os.listdir(TEST_IMAGES_DIR) if os.path.isfile(os.path.join(TEST_IMAGES_DIR, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    if test_images:\n",
    "        # Sélectionner une image aléatoire\n",
    "        test_img = random.choice(test_images)\n",
    "        test_img_path = os.path.join(TEST_IMAGES_DIR, test_img)\n",
    "        \n",
    "        print(f\"Test du modèle sur l'image: {test_img}\")\n",
    "        detection_pred, classification_pred, probs = predict_single_image(model, test_img_path, detection_classes, classification_classes)\n",
    "        \n",
    "        if detection_pred is not None:\n",
    "            print(f\"Prédiction de détection: {detection_pred} (probabilité: {probs['detection_prob']:.2f})\")\n",
    "            if classification_pred is not None:\n",
    "                print(f\"Prédiction de classification: {classification_pred} (probabilité: {probs['classification_prob']:.2f})\")\n",
    "            else:\n",
    "                print(\"Prédiction de classification: N/A\")\n",
    "            \n",
    "            # Visualiser la prédiction\n",
    "            visualize_prediction(test_img_path, detection_pred, classification_pred, probs)\n",
    "        else:\n",
    "            print(\"Erreur lors de la prédiction.\")\n",
    "    else:\n",
    "        print(\"Aucune image de test trouvée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Prédiction sur toutes les images de test\n",
    "\n",
    "Testons notre modèle sur toutes les images de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all_test_images(model, test_dir, detection_classes, classification_classes):\n",
    "    \"\"\"Prédit la classe de toutes les images de test.\"\"\"\n",
    "    # Obtenir la liste des images de test\n",
    "    test_images = [f for f in os.listdir(test_dir) if os.path.isfile(os.path.join(test_dir, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    if not test_images:\n",
    "        print(\"Aucune image de test trouvée.\")\n",
    "        return None\n",
    "    \n",
    "    # Prédire pour chaque image\n",
    "    results = []\n",
    "    for img_name in test_images:\n",
    "        img_path = os.path.join(test_dir, img_name)\n",
    "        \n",
    "        # Extraire la vraie classe à partir du nom de fichier\n",
    "        true_class = None\n",
    "        for cls in classification_classes:\n",
    "            if cls in img_name:\n",
    "                true_class = cls\n",
    "                break\n",
    "        \n",
    "        if 'non_plum' in img_name:\n",
    "            true_detection = 'non_plum'\n",
    "            true_class = None\n",
    "        else:\n",
    "            true_detection = 'plum'\n",
    "        \n",
    "        # Prédire\n",
    "        detection_pred, classification_pred, probs = predict_single_image(model, img_path, detection_classes, classification_classes)\n",
    "        \n",
    "        # Ajouter aux résultats\n",
    "        results.append({\n",
    "            'img_name': img_name,\n",
    "            'img_path': img_path,\n",
    "            'true_detection': true_detection,\n",
    "            'true_class': true_class,\n",
    "            'detection_pred': detection_pred,\n",
    "            'classification_pred': classification_pred,\n",
    "            'probs': probs\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def visualize_test_results(results):\n",
    "    \"\"\"Visualise les résultats des prédictions sur les images de test.\"\"\"\n",
    "    if not results:\n",
    "        print(\"Aucun résultat à visualiser.\")\n",
    "        return\n",
    "    \n",
    "    # Calculer les métriques de détection\n",
    "    detection_correct = sum(1 for r in results if r['true_detection'] == r['detection_pred'])\n",
    "    detection_accuracy = detection_correct / len(results)\n",
    "    \n",
    "    # Calculer les métriques de classification\n",
    "    classification_results = [r for r in results if r['true_detection'] == 'plum' and r['detection_pred'] == 'plum']\n",
    "    classification_correct = sum(1 for r in classification_results if r['true_class'] == r['classification_pred'])\n",
    "    classification_accuracy = classification_correct / len(classification_results) if classification_results else 0\n",
    "    \n",
    "    # Afficher les métriques\n",
    "    print(f\"Résultats sur {len(results)} images de test:\")\n",
    "    print(f\"Précision de détection: {detection_accuracy:.2f} ({detection_correct}/{len(results)})\")\n",
    "    print(f\"Précision de classification: {classification_accuracy:.2f} ({classification_correct}/{len(classification_results)})\")\n",
    "    \n",
    "    # Créer une matrice de confusion pour la détection\n",
    "    detection_true = [r['true_detection'] for r in results]\n",
    "    detection_pred = [r['detection_pred'] for r in results]\n",
    "    detection_classes_unique = sorted(list(set(detection_true + detection_pred)))\n",
    "    \n",
    "    detection_cm = confusion_matrix(detection_true, detection_pred, labels=detection_classes_unique)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    sns.heatmap(detection_cm, annot=True, fmt='d', cmap='Blues', xticklabels=detection_classes_unique, yticklabels=detection_classes_unique)\n",
    "    plt.title('Matrice de confusion - Détection')\n",
    "    plt.ylabel('Vraie classe')\n",
    "    plt.xlabel('Classe prédite')\n",
    "    \n",
    "    # Créer une matrice de confusion pour la classification\n",
    "    if classification_results:\n",
    "        classification_true = [r['true_class'] for r in classification_results]\n",
    "        classification_pred = [r['classification_pred'] for r in classification_results]\n",
    "        classification_classes_unique = sorted(list(set([c for c in classification_true + classification_pred if c is not None])))\n",
    "        \n",
    "        classification_cm = confusion_matrix(classification_true, classification_pred, labels=classification_classes_unique)\n",
    "        \n",
    "        plt.subplot(2, 1, 2)\n",
    "        sns.heatmap(classification_cm, annot=True, fmt='d', cmap='Blues', xticklabels=classification_classes_unique, yticklabels=classification_classes_unique)\n",
    "        plt.title('Matrice de confusion - Classification')\n",
    "        plt.ylabel('Vraie classe')\n",
    "        plt.xlabel('Classe prédite')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Afficher quelques exemples de prédictions\n",
    "    num_examples = min(5, len(results))\n",
    "    plt.figure(figsize=(15, 4 * num_examples))\n",
    "    \n",
    "    for i in range(num_examples):\n",
    "        result = results[i]\n",
    "        img = Image.open(result['img_path']).convert('RGB')\n",
    "        \n",
    "        plt.subplot(num_examples, 2, 2*i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Image: {result['img_name']}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(num_examples, 2, 2*i + 2)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Texte de prédiction\n",
    "        text = f\"Vraie détection: {result['true_detection']}\\n\"\n",
    "        text += f\"Prédiction de détection: {result['detection_pred']} ({result['probs']['detection_prob']:.2f})\\n\\n\"\n",
    "        \n",
    "        if result['true_class'] is not None:\n",
    "            text += f\"Vraie classe: {result['true_class']}\\n\"\n",
    "        else:\n",
    "            text += \"Vraie classe: N/A\\n\"\n",
    "        \n",
    "        if result['classification_pred'] is not None:\n",
    "            text += f\"Prédiction de classification: {result['classification_pred']} ({result['probs']['classification_prob']:.2f})\"\n",
    "        else:\n",
    "            text += \"Prédiction de classification: N/A\"\n",
    "        \n",
    "        plt.text(0.1, 0.5, text, fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Tester le modèle sur toutes les images de test\n",
    "if 'model' in locals():\n",
    "    print(\"Test du modèle sur toutes les images de test...\")\n",
    "    results = predict_all_test_images(model, TEST_IMAGES_DIR, detection_classes, classification_classes)\n",
    "    \n",
    "    if results:\n",
    "        visualize_test_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test interactif avec téléchargement d'images (pour Google Colab)\n",
    "\n",
    "Si vous êtes dans Google Colab, vous pouvez télécharger vos propres images pour les tester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB and 'model' in locals():\n",
    "    from google.colab import files\n",
    "    \n",
    "    def test_uploaded_image():\n",
    "        print(\"Veuillez télécharger une image à tester.\")\n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        for filename in uploaded.keys():\n",
    "            # Sauvegarder l'image téléchargée\n",
    "            img_path = os.path.join(TEST_IMAGES_DIR, filename)\n",
    "            with open(img_path, 'wb') as f:\n",
    "                f.write(uploaded[filename])\n",
    "            \n",
    "            print(f\"Test du modèle sur l'image téléchargée: {filename}\")\n",
    "            detection_pred, classification_pred, probs = predict_single_image(model, img_path, detection_classes, classification_classes)\n",
    "            \n",
    "            if detection_pred is not None:\n",
    "                print(f\"Prédiction de détection: {detection_pred} (probabilité: {probs['detection_prob']:.2f})\")\n",
    "                if classification_pred is not None:\n",
    "                    print(f\"Prédiction de classification: {classification_pred} (probabilité: {probs['classification_prob']:.2f})\")\n",
    "                else:\n",
    "                    print(\"Prédiction de classification: N/A\")\n",
    "                \n",
    "                # Visualiser la prédiction\n",
    "                visualize_prediction(img_path, detection_pred, classification_pred, probs)\n",
    "            else:\n",
    "                print(\"Erreur lors de la prédiction.\")\n",
    "    \n",
    "    # Décommentez la ligne suivante pour tester avec vos propres images\n",
    "    # test_uploaded_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "Dans ce notebook, nous avons utilisé les fonctions existantes des modules `data_preprocessing` et `model_architecture` pour :\n",
    "1. Télécharger et préparer des images de test à partir du jeu de données Kaggle \"African Plums Dataset\"\n",
    "2. Charger le modèle à deux étapes entraîné précédemment\n",
    "3. Tester le modèle sur des images individuelles\n",
    "4. Évaluer les performances du modèle sur un ensemble d'images de test\n",
    "5. Tester le modèle sur des images téléchargées par l'utilisateur (dans Google Colab)\n",
    "\n",
    "Le modèle est maintenant prêt à être utilisé pour classifier des prunes africaines en fonction de leur qualité et de leurs défauts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
